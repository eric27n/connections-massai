{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYT Connections Notebook\n",
    "\n",
    "**PLEASE READ:** Python notebooks are a pain in the ass to try and merge in Github. This means that if you make an edit here, but someone else already made changes to this file, then trying to complete a git merge will be much harder for this file than, say, a normal Python file. This ultimately boils down to an ipynb *technically* being a JSON, and there's a lot of things going on under the hood that makes conflicts much more likely (incidentally, this is also the reason why if you and multiple people try to work on the same file on Google Colab, you're going to get messages about \"unable to save local changes\" and conflicts). As a result, **please do not modify this file.** Instead, **create a copy of this file and make your changes there** (e.g. `connections-notebook-[your-name].ipynb`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gzip\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import io\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import gensim.downloader as api\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from itertools import combinations\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Games & Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628 {'words': ['snow', 'level', 'shift', 'kayak', 'heat', 'tab', 'bucks', 'return', 'jazz', 'hail', 'option', 'rain', 'sleet', 'racecar', 'mom', 'nets'], 'solution': {'groups': [{'words': ['shift', 'tab', 'return', 'option'], 'reason': 'keyboard keys'}, {'words': ['heat', 'bucks', 'jazz', 'nets'], 'reason': 'nba teams'}, {'words': ['level', 'kayak', 'racecar', 'mom'], 'reason': 'palindromes'}, {'words': ['snow', 'hail', 'rain', 'sleet'], 'reason': 'wet weather'}]}}\n"
     ]
    }
   ],
   "source": [
    "# Read in games from HuggingFace dataset\n",
    "df_ = pd.read_csv(\"hf://datasets/eric27n/NYT-Connections/Connections_Data.csv\")\n",
    "df_['Word'] = df_['Word'].fillna(\"NA\")\n",
    "df_['Word'] = df_['Word'].str.lower()\n",
    "df_['Group Name'] = df_['Group Name'].str.lower()\n",
    "grouped = df_.groupby('Game ID')\n",
    "result = []\n",
    "\n",
    "for game_id, group in grouped:\n",
    "  words = group['Word'].tolist()\n",
    "  group_by_name = group.groupby('Group Name')\n",
    "  solution = []\n",
    "  \n",
    "  for group_name, sub_group in group_by_name:\n",
    "    group_words = sub_group['Word'].tolist()\n",
    "    reason = sub_group['Group Name'].iloc[0]\n",
    "    solution.append({'words': group_words, 'reason': reason})\n",
    "\n",
    "  result.append({'words': words, 'solution': {'groups': solution}})\n",
    "\n",
    "ds = result\n",
    "ds_len = len(ds)\n",
    "print(len(ds), ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE NEWS: [('denver', 0.6403177976608276), ('chicago', 0.6305170059204102), ('houston', 0.6260292530059814), ('boston', 0.6210216283798218), ('nyc', 0.6082404851913452), ('atlanta', 0.6007115244865417), ('cleveland', 0.5984835624694824), ('philadelphia', 0.5938323736190796), ('oakland', 0.592968225479126), ('orlando', 0.592677891254425)]\n",
      "GLOVE: [('oakland', 0.6306731104850769), ('portland', 0.6112086772918701), ('mariners', 0.5879033207893372), ('francisco', 0.5715591907501221), ('denver', 0.5678620934486389), ('chicago', 0.5588996410369873), ('cleveland', 0.5522618889808655), ('angeles', 0.5507204532623291), ('milwaukee', 0.548105001449585), ('tampa', 0.5452930331230164)]\n",
      "WIKI: [('minneapolis', 0.728505551815033), ('portland', 0.7126332521438599), ('vancouver', 0.6863006949424744), ('calgary', 0.6720302104949951), ('philadelphia', 0.6713477373123169), ('baltimore', 0.6664227247238159), ('houston', 0.6611942052841187), ('denver', 0.6545454859733582), ('melbourne', 0.6510372757911682), ('pittsburgh', 0.6482068300247192)]\n",
      "NUMBERBATCH: [('university_of_washington', 0.9806408286094666), ('space_needle', 0.9797334671020508), ('seattleite', 0.9641170501708984), ('emerald_city', 0.9455490112304688), ('tacoma', 0.7643471360206604), ('spokane', 0.7531239986419678), ('portland', 0.7523225545883179), ('lake_chelan', 0.7268684506416321), ('washington', 0.7256752252578735), ('kennewick', 0.7251202464103699)]\n"
     ]
    }
   ],
   "source": [
    "# Import different models\n",
    "model_google = api.load('word2vec-google-news-300')\n",
    "model_glove = api.load('glove-wiki-gigaword-300')\n",
    "model_wiki = api.load('fasttext-wiki-news-subwords-300')\n",
    "\n",
    "print(f\"GOOGLE NEWS: {model_google.most_similar('seattle')}\")\n",
    "print(f\"GLOVE: {model_glove.most_similar('seattle')}\")\n",
    "print(f\"WIKI: {model_wiki.most_similar('seattle')}\")\n",
    "\n",
    "# Additional fourth model\n",
    "# From my tests, this model did the best, albeit it requires a large download beforehand\n",
    "# NEVER UPLOAD THE ZIPPED OR UNZIPPED TEXT FILE TO GITHUB\n",
    "#     IF YOU DO, YOU WILL GET AN ERROR AND TRYING TO UNDO THESE CHANGES WILL BE A PAIN IN THE ASS\n",
    "# https://github.com/commonsense/conceptnet-numberbatch\n",
    "gzipped_file_path = 'numberbatch-en-19.08.txt.gz'\n",
    "with gzip.open(gzipped_file_path, 'rt', encoding='utf-8') as f_in:\n",
    "    decompressed_data = f_in.read()\n",
    "decompressed_file = io.BytesIO(decompressed_data.encode('utf-8'))\n",
    "model_numberbatch = KeyedVectors.load_word2vec_format(decompressed_file, binary=False)\n",
    "print(f\"NUMBERBATCH: {model_numberbatch.most_similar('seattle')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on one round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess multi-word expressions (e.g. 'New York', 'push-up')\n",
    "def preprocess_word(word, model):\n",
    "  \"\"\"\n",
    "  Preprocess multi-word expressions (MWE) for accomodation by word2vec models.\n",
    "\n",
    "  Args:\n",
    "      word (str): The word to preprocess.\n",
    "      model (gensim.models.word2vec): The word2vec model to check for MWE.\n",
    "\n",
    "  Returns:\n",
    "      str: The preprocessed word.\n",
    "  \"\"\"\n",
    "  mwe = re.sub(r'[-\\s]', '_', word.lower())\n",
    "  \n",
    "  if mwe not in model:\n",
    "      mwe = re.sub(r'_', '', mwe)\n",
    "  \n",
    "  return mwe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract words from ds[i]['words']\n",
    "def guess(model, words):\n",
    "  \"\"\"\n",
    "  Guess the best 4 words to form a group based on word similarity.\n",
    "  \n",
    "  Args:\n",
    "      model (gensim.models.word2vec): The word2vec model to use.\n",
    "      words (list): A list of words to process.\n",
    "  \n",
    "  Returns:\n",
    "      list: A list of the best 4 words to form a group.\n",
    "  \"\"\"\n",
    "  \n",
    "  # Preprocess words for the model, create similarity matrix to find similarities among words\n",
    "  words = [preprocess_word(word, model) for word in words]\n",
    "  similarity_matrix = np.zeros((len(words), len(words)))\n",
    "  for i, word1 in enumerate(words):\n",
    "      for j, word2 in enumerate(words):\n",
    "          if word1 in model and word2 in model:\n",
    "              similarity_matrix[i, j] = model.similarity(word1, word2)\n",
    "          else:\n",
    "              similarity_matrix[i, j] = 0\n",
    "\n",
    "  # Convert the similarity matrix to a DataFrame for easier manipulation\n",
    "  similarity_df = pd.DataFrame(similarity_matrix, index=words, columns=words)\n",
    "  _max = 0\n",
    "  argmax = 0\n",
    "  argword = \"\"\n",
    "  \n",
    "  # Find the word with the highest similarity to the first word\n",
    "  for idx, word in enumerate(words):\n",
    "    if type(similarity_df[word]) is pd.DataFrame:\n",
    "      print(similarity_df[word])\n",
    "    similar_words = similarity_df[word].sort_values(ascending=False)\n",
    "    if similar_words.iloc[1] > _max:\n",
    "      _max = similar_words.iloc[1]\n",
    "      argmax = idx\n",
    "      argword = similar_words.index[1]\n",
    "\n",
    "  # Initialize the build list with the most similar pair of words\n",
    "  build_list = [words[argmax], argword]\n",
    "\n",
    "  # Create a copy of the original words list to avoid modifying it\n",
    "  words_copy = words.copy()\n",
    "  \n",
    "  # Finding the third most similar word to the build list\n",
    "  # Remove the most similar pair from the original words list\n",
    "  for test_word in build_list:\n",
    "    if test_word not in words_copy:\n",
    "      return None\n",
    "    words_copy.remove(test_word)\n",
    "\n",
    "  # Calculate average similarity of remaining words to the build list\n",
    "  sim_list = []\n",
    "  for test_word in words_copy:\n",
    "    similarities = []\n",
    "    for train_word in build_list:\n",
    "        if train_word in model and test_word in model:\n",
    "            similarity = model.similarity(train_word, test_word)\n",
    "            similarities.append(similarity)\n",
    "        else:\n",
    "            similarities.append(0)  # Handle words not in the model\n",
    "    average_similarity = sum(similarities) / len(similarities)\n",
    "    sim_list.append(average_similarity)\n",
    "\n",
    "  # Find the word with the highest average similarity to the build list\n",
    "  index_of_highest_value = sim_list.index(max(sim_list))\n",
    "  build_list.append(words_copy[index_of_highest_value])\n",
    "\n",
    "  # Finding the fourth most similar word to the build list\n",
    "  # Pretty much same code as the third most similar word\n",
    "  words_copy = words.copy()\n",
    "  for test_word in build_list:\n",
    "    if test_word not in words_copy:\n",
    "      return None\n",
    "    words_copy.remove(test_word)\n",
    "\n",
    "  sim_list = []\n",
    "  for test_word in words_copy:\n",
    "    similarities = []\n",
    "    for train_word in build_list:\n",
    "        if train_word in model and test_word in model:\n",
    "            similarity = model.similarity(train_word, test_word)\n",
    "            similarities.append(similarity)\n",
    "        else:\n",
    "            similarities.append(0)  # Handle words not in the model\n",
    "    average_similarity = sum(similarities) / len(similarities)\n",
    "    sim_list.append(average_similarity)\n",
    "\n",
    "  index_of_highest_value = sim_list.index(max(sim_list))\n",
    "  build_list.append(words_copy[index_of_highest_value])\n",
    "\n",
    "  # Return the final list of four words\n",
    "  return build_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_round(guess_list, solution):\n",
    "  \"\"\"\n",
    "  Evaluate the guess list against the solution.\n",
    "\n",
    "  Args:\n",
    "      guess_list (list): The list of guessed words. Should contain 4 entries.\n",
    "      solution (dict): The solution dictionary containing the correct groups.\n",
    "\n",
    "  Returns:\n",
    "      int: The maximum number of correct guesses in any group.\n",
    "  \"\"\"\n",
    "  # right_count evaluates the number of correct guesses in each group\n",
    "  right_count = [0, 0, 0, 0]\n",
    "  \n",
    "  # Check if the guess list is valid\n",
    "  if len(guess_list) != 4:\n",
    "    return None\n",
    "  \n",
    "  # Check if the guess list aligns with a solution\n",
    "  for final_word in guess_list:\n",
    "    for idx, group in enumerate(solution['groups']):\n",
    "      if final_word in group['words']:\n",
    "        right_count[idx] += 1\n",
    "  \n",
    "  # Return the maximum number of correct guesses in any group\n",
    "  # If the guess was all right, then the max will be 4\n",
    "  return max(right_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Google News ========\n",
      "AVERAGE SCORE: 2.9106858054226477\n",
      "1: 19\n",
      "2: 179\n",
      "3: 268\n",
      "4: 161\n",
      "\n",
      "======== Glove ========\n",
      "AVERAGE SCORE: 2.8086124401913874\n",
      "1: 22\n",
      "2: 225\n",
      "3: 231\n",
      "4: 149\n",
      "\n",
      "======== Wikipedia ========\n",
      "AVERAGE SCORE: 2.9649122807017543\n",
      "1: 18\n",
      "2: 177\n",
      "3: 241\n",
      "4: 191\n",
      "\n",
      "======== Numberbatch ========\n",
      "AVERAGE SCORE: 3.0637958532695375\n",
      "1: 28\n",
      "2: 127\n",
      "3: 249\n",
      "4: 223\n",
      "\n",
      "Number of Games with At Least One Good First Guess: 335 / 628\n"
     ]
    }
   ],
   "source": [
    "models = [model_google, model_glove, model_wiki, model_numberbatch]\n",
    "model_names = [\"Google News\", \"Glove\", \"Wikipedia\", \"Numberbatch\"]\n",
    "correct_idx = []\n",
    "for idx, model in enumerate(models):\n",
    "  print(f\"======== {model_names[idx]} ========\")\n",
    "  right_list = []\n",
    "  one_away_when = []\n",
    "  for i in range(ds_len):\n",
    "    guess_list = guess(model, ds[i]['words'])\n",
    "    if guess_list is not None:\n",
    "      score = eval_round(guess_list, ds[i]['solution'])\n",
    "      right_list.append(score)\n",
    "      if score == 4 and i not in correct_idx:\n",
    "        correct_idx.append(i)\n",
    "\n",
    "  print(f\"AVERAGE SCORE: {sum(right_list) / len(right_list)}\")\n",
    "  for i in range(1, 5):\n",
    "    print(f\"{i}: {right_list.count(i)}\")\n",
    "  print()\n",
    "print(f\"Number of Games with At Least One Good First Guess: {len(correct_idx)} / {ds_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_matrix(model, words):\n",
    "    words = [preprocess_word(word, model) for word in words]\n",
    "    words = [word for word in words if word in model]\n",
    "    \n",
    "    similarity_matrix = {}\n",
    "    for i, word1 in enumerate(words):\n",
    "        for j, word2 in enumerate(words):\n",
    "            if i < j:  # Avoid redundant computations\n",
    "                similarity_matrix[(word1, word2)] = model.similarity(word1, word2)\n",
    "    return similarity_matrix\n",
    "\n",
    "# Extract words from ds[i]['words'] with fallback guesses\n",
    "# similarity_matrix: precomputed similarity matrix\n",
    "\n",
    "def guess_best_combination(model, words, similarity_matrix=None, lives=4):\n",
    "    if len(words) == 4:\n",
    "        return [list(words) * lives]\n",
    "    words = [preprocess_word(word, model) for word in words]\n",
    "    words = [word for word in words if word in model]\n",
    "\n",
    "    if len(words) < 4 or lives < 1:\n",
    "        return None\n",
    "\n",
    "    if similarity_matrix is None:\n",
    "        similarity_matrix = compute_similarity_matrix(model, words)\n",
    "\n",
    "    all_combinations = list(combinations(words, 4))\n",
    "    scored_combinations = []\n",
    "\n",
    "    for combination in all_combinations:\n",
    "        similarities = []\n",
    "        for i, word1 in enumerate(combination):\n",
    "            for j, word2 in enumerate(combination):\n",
    "                if i < j:\n",
    "                    similarities.append(similarity_matrix.get((word1, word2), similarity_matrix.get((word2, word1), 0)))\n",
    "\n",
    "        average_similarity = np.mean(similarities)\n",
    "        scored_combinations.append((combination, average_similarity))\n",
    "\n",
    "    # Sort combinations by average similarity in descending order\n",
    "    scored_combinations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Return up to four attempts in descending order of similarity\n",
    "    top_guesses = [list(comb[0]) for comb in scored_combinations[:lives]]\n",
    "    return top_guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['win', 'score', 'earn', 'crowd'], ['host', 'win', 'score', 'earn'], ['win', 'score', 'flock', 'earn'], ['win', 'score', 'land', 'earn']]\n"
     ]
    }
   ],
   "source": [
    "print(guess_best_combination(model_google, ['host', 'light', 'win', 'yang', 'score', 'masculine', 'flock', 'land', 'expansive', 'sea', 'earn', 'crowd']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Correct with 0 strikes: 9.0\n",
      "All Correct with 1 strike: 8.1\n",
      "2 Correct Groups - 2 strikes: 2.25\n"
     ]
    }
   ],
   "source": [
    "def calculate_score(num_correct, strikes):\n",
    "    \"\"\"\n",
    "    Calculate the score based on the number of correct guesses and strikes.\n",
    "    \n",
    "    Args:\n",
    "        num_correct (int): The number of correct guesses (0-4).\n",
    "        strikes (int): The number of strikes (0-4).\n",
    "    \n",
    "    Returns:\n",
    "        float: The calculated score.\n",
    "    \"\"\"\n",
    "    # Define multipliers and penalties\n",
    "    multipliers = [1, 2, 3, 3]\n",
    "    penalties = [1.0, 0.9, 0.75, 0.5, 0.25]\n",
    "\n",
    "    # Ensure the number of correct groups is within the valid range\n",
    "    if num_correct > 4:\n",
    "        num_correct = 4\n",
    "\n",
    "    # Calculate the total score\n",
    "    total_score = 0\n",
    "    for i in range(num_correct):\n",
    "        total_score += 1 * multipliers[i] * penalties[strikes]\n",
    "\n",
    "    return np.round(total_score, 2)\n",
    "\n",
    "# Example usage\n",
    "num_correct_1 = 4\n",
    "num_correct_2 = 4\n",
    "num_correct_3 = 2\n",
    "\n",
    "strikes_1 = 0\n",
    "strikes_2 = 1\n",
    "strikes_3 = 2\n",
    "\n",
    "print(\"All Correct with 0 strikes:\", calculate_score(num_correct_1, strikes_1))  # Output: 9.0\n",
    "print(\"All Correct with 1 strike:\", calculate_score(num_correct_2, strikes_2))   # Output: 8.1\n",
    "print(\"2 Correct Groups - 2 strikes:\", calculate_score(num_correct_3, strikes_3)) # Output: 2.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Google News ========\n",
      "AVERAGE SCORE: 0.893312101910828\n",
      "0: 323\n",
      "1: 169\n",
      "2: 76\n",
      "3: 0\n",
      "4: 60\n",
      "Average Total Score: 0.8366242038216564 (Total: 525.4000000000002)\n",
      "\n",
      "======== Glove ========\n",
      "AVERAGE SCORE: 0.8136942675159236\n",
      "0: 335\n",
      "1: 167\n",
      "2: 80\n",
      "3: 0\n",
      "4: 46\n",
      "Average Total Score: 0.6980095541401274 (Total: 438.35)\n",
      "\n",
      "======== Wikipedia ========\n",
      "AVERAGE SCORE: 1.1767515923566878\n",
      "0: 264\n",
      "1: 175\n",
      "2: 96\n",
      "3: 0\n",
      "4: 93\n",
      "Average Total Score: 1.240525477707007 (Total: 779.0500000000003)\n",
      "\n",
      "======== Numberbatch ========\n",
      "GAME 601: 1 correct guesses, 0 lives left\n",
      "GAME 602: 4 correct guesses, 4 lives left\n",
      "GAME 603: 1 correct guesses, 0 lives left\n",
      "GAME 604: 4 correct guesses, 2 lives left\n",
      "GAME 605: 1 correct guesses, 0 lives left\n",
      "GAME 606: 1 correct guesses, 0 lives left\n",
      "GAME 607: 0 correct guesses, 0 lives left\n",
      "GAME 608: 1 correct guesses, 0 lives left\n",
      "GAME 609: 2 correct guesses, 0 lives left\n",
      "GAME 610: 2 correct guesses, 0 lives left\n",
      "GAME 611: 2 correct guesses, 0 lives left\n",
      "GAME 612: 2 correct guesses, 0 lives left\n",
      "GAME 613: 0 correct guesses, 0 lives left\n",
      "GAME 614: 0 correct guesses, 0 lives left\n",
      "GAME 615: 4 correct guesses, 4 lives left\n",
      "GAME 616: 4 correct guesses, 4 lives left\n",
      "GAME 617: 0 correct guesses, 0 lives left\n",
      "GAME 618: 0 correct guesses, 0 lives left\n",
      "GAME 619: 2 correct guesses, 0 lives left\n",
      "GAME 620: 2 correct guesses, 0 lives left\n",
      "GAME 621: 0 correct guesses, 0 lives left\n",
      "GAME 622: 4 correct guesses, 3 lives left\n",
      "GAME 623: 1 correct guesses, 0 lives left\n",
      "GAME 624: 2 correct guesses, 0 lives left\n",
      "GAME 625: 1 correct guesses, 0 lives left\n",
      "GAME 626: 1 correct guesses, 0 lives left\n",
      "GAME 627: 4 correct guesses, 4 lives left\n",
      "AVERAGE SCORE: 1.5318471337579618\n",
      "0: 199\n",
      "1: 170\n",
      "2: 122\n",
      "3: 0\n",
      "4: 137\n",
      "Average Total Score: 1.819187898089172 (Total: 1142.45)\n",
      "\n",
      "Number of Games with At Least One Complete Solve: 175 / 628\n"
     ]
    }
   ],
   "source": [
    "models = [model_google, model_glove, model_wiki, model_numberbatch]\n",
    "model_names = [\"Google News\", \"Glove\", \"Wikipedia\", \"Numberbatch\"]\n",
    "correct_idx = []\n",
    "multiplier = {4: 1.0, 3: 0.9, 2: 0.75, 1: 0.5, 0: 0.25}\n",
    "\n",
    "# Iterate through each model and evaluate the guesses\n",
    "for idx, model in enumerate(models):\n",
    "  print(f\"======== {model_names[idx]} ========\")\n",
    "  right_list = []\n",
    "  correct_guesses = []\n",
    "  total_scores = []\n",
    "  one_away_when = []\n",
    "  for i in range(ds_len):\n",
    "    #print(\"I:\", i)\n",
    "    lives = 4\n",
    "    correct_count = 0\n",
    "    total_score = 0\n",
    "    options = ds[i]['words']\n",
    "    while lives > 0 and len(options) > 0:\n",
    "      #print(\"LEN:\", len(options))\n",
    "      guess_list = guess_best_combination(model, options, lives=lives)\n",
    "      #print(\"GUESS:\", guess_list)\n",
    "      if guess_list is None:\n",
    "        lives -= 1\n",
    "        continue\n",
    "      if guess_list is not None:\n",
    "        for guess in guess_list:\n",
    "          score = eval_round(guess, ds[i]['solution'])\n",
    "          if score == 4:\n",
    "            correct_count += 1\n",
    "            right_list.append(score)\n",
    "            options = [item for item in options if item not in guess]\n",
    "            if len(options) == 4:\n",
    "              correct_count += 1\n",
    "              options = []\n",
    "            break\n",
    "          lives -= 1\n",
    "          if guess == guess_list[-1] or lives == 0:\n",
    "            right_list.append(score)\n",
    "            break\n",
    "    correct_guesses.append(correct_count)\n",
    "    if model == model_numberbatch and i > 600:\n",
    "      print(f\"GAME {i}: {correct_count} correct guesses, {lives} lives left\")\n",
    "    total_scores.append(calculate_score(correct_count, 4 - lives))\n",
    "    if correct_count == 4 and i not in correct_idx:\n",
    "      correct_idx.append(i)\n",
    "\n",
    "  print(f\"AVERAGE SCORE: {sum(correct_guesses) / len(correct_guesses)}\")\n",
    "  for i in range(0, 5):\n",
    "    print(f\"{i}: {correct_guesses.count(i)}\")\n",
    "  print(f\"Average Total Score: {sum(total_scores) / len(total_scores)} (Total: {sum(total_scores)})\")\n",
    "  print()\n",
    "print(f\"Number of Games with At Least One Complete Solve: {len(correct_idx)} / {ds_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "description = \"You are an assistant configured to solve the New York Times Connections Word game.\"\n",
    "prompt = \"\"\"\n",
    "You are an assistant configured to solve the New York Times Connections Word game.\n",
    "Out of the given words, please return a group of 4 words that you are most confident are related to each other.\n",
    "Please output your response in a JSON format with the following structure:\n",
    "{\n",
    "  \"words\": [\"word1\", \"word2\", \"word3\", \"word4\"],\n",
    "  \"reason\": \"Your reasoning here.\"\n",
    "}\n",
    "\n",
    "You may assume the following:\n",
    "1. The provided list of words will always be a multiple of four, and a group of four words will always exist.\n",
    "2. Every word in the provided list is part of a group of four words, but you only need to make one guess.\n",
    "3. There will never be a \"miscellaneous\" group, and no word will be part of more than one group.\n",
    "4. A red herring category may be present, where some words appear to be related but are not part of the correct group.\n",
    "\n",
    "Please give your answer in a JSON format and do not provide any other text. Your words to choose from are as follows:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': ['level', 'racecar', 'kayak', 'mom'], 'reason': 'They are all palindromic words.'}\n"
     ]
    }
   ],
   "source": [
    "words = \", \".join(ds[0]['words'])\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": description},\n",
    "    {\"role\": \"user\", \"content\": prompt + words}\n",
    "  ],\n",
    "  max_completion_tokens=500,\n",
    "  response_format={ \"type\": \"json_object\" }\n",
    ")\n",
    "response = response.choices[0].message.content\n",
    "response = json.loads(response)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "Due: 6 March 2025\n",
    "\n",
    "Group 1:\n",
    "1. Write some code to try and better save attributes of results!\n",
    "    * Ex: What are the guesses that are being made? What does each game look like?\n",
    "    * I recommend saving the results as a JSON for organization, but feel free to decide how you'd like to save your results.\n",
    "2. Generate a graph of some kind that can give some insights!\n",
    "    * E.g. What kinds of groups are most commonly solved? What do you see with groups that are solved? What kinds of group difficulties are solved most often?\n",
    "\n",
    "Group 2:\n",
    "* Devise a better guessing algorithm, and implement it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
