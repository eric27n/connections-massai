{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYT Connections Notebook\n",
    "\n",
    "**PLEASE READ:** Python notebooks are a pain in the ass to try and merge in Github. This means that if you make an edit here, but someone else already made changes to this file, then trying to complete a git merge will be much harder for this file than, say, a normal Python file. This ultimately boils down to an ipynb *technically* being a JSON, and there's a lot of things going on under the hood that makes conflicts much more likely (incidentally, this is also the reason why if you and multiple people try to work on the same file on Google Colab, you're going to get messages about \"unable to save local changes\" and conflicts). As a result, **please do not modify this file.** Instead, **create a copy of this file and make your changes there** (e.g. `connections-notebook-[your-name].ipynb`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gzip\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import io\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import gensim.downloader as api\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from itertools import combinations\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Games & Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628 {'words': ['snow', 'level', 'shift', 'kayak', 'heat', 'tab', 'bucks', 'return', 'jazz', 'hail', 'option', 'rain', 'sleet', 'racecar', 'mom', 'nets'], 'solution': {'groups': [{'words': ['shift', 'tab', 'return', 'option'], 'reason': 'keyboard keys'}, {'words': ['heat', 'bucks', 'jazz', 'nets'], 'reason': 'nba teams'}, {'words': ['level', 'kayak', 'racecar', 'mom'], 'reason': 'palindromes'}, {'words': ['snow', 'hail', 'rain', 'sleet'], 'reason': 'wet weather'}]}}\n"
     ]
    }
   ],
   "source": [
    "# Read in games from HuggingFace dataset\n",
    "df_ = pd.read_csv(\"hf://datasets/eric27n/NYT-Connections/Connections_Data.csv\")\n",
    "df_['Word'] = df_['Word'].fillna(\"NA\")\n",
    "df_['Word'] = df_['Word'].str.lower()\n",
    "df_['Group Name'] = df_['Group Name'].str.lower()\n",
    "grouped = df_.groupby('Game ID')\n",
    "result = []\n",
    "\n",
    "for game_id, group in grouped:\n",
    "  words = group['Word'].tolist()\n",
    "  group_by_name = group.groupby('Group Name')\n",
    "  solution = []\n",
    "  \n",
    "  for group_name, sub_group in group_by_name:\n",
    "    group_words = sub_group['Word'].tolist()\n",
    "    reason = sub_group['Group Name'].iloc[0]\n",
    "    solution.append({'words': group_words, 'reason': reason})\n",
    "\n",
    "  result.append({'words': words, 'solution': {'groups': solution}})\n",
    "\n",
    "ds = result\n",
    "ds_len = len(ds)\n",
    "print(len(ds), ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBERBATCH: [('university_of_washington', 0.9806408286094666), ('space_needle', 0.9797334671020508), ('seattleite', 0.9641170501708984), ('emerald_city', 0.9455490112304688), ('tacoma', 0.7643471360206604), ('spokane', 0.7531239986419678), ('portland', 0.7523225545883179), ('lake_chelan', 0.7268684506416321), ('washington', 0.7256752252578735), ('kennewick', 0.7251202464103699)]\n"
     ]
    }
   ],
   "source": [
    "# Import different models\n",
    "# model_google = api.load('word2vec-google-news-300')\n",
    "# model_glove = api.load('glove-wiki-gigaword-300')\n",
    "# model_wiki = api.load('fasttext-wiki-news-subwords-300')\n",
    "\n",
    "# print(f\"GOOGLE NEWS: {model_google.most_similar('seattle')}\")\n",
    "# print(f\"GLOVE: {model_glove.most_similar('seattle')}\")\n",
    "# print(f\"WIKI: {model_wiki.most_similar('seattle')}\")\n",
    "\n",
    "# Additional fourth model\n",
    "# From my tests, this model did the best, albeit it requires a large download beforehand\n",
    "# NEVER UPLOAD THE ZIPPED OR UNZIPPED TEXT FILE TO GITHUB\n",
    "#     IF YOU DO, YOU WILL GET AN ERROR AND TRYING TO UNDO THESE CHANGES WILL BE A PAIN IN THE ASS\n",
    "# https://github.com/commonsense/conceptnet-numberbatch\n",
    "gzipped_file_path = 'numberbatch-en-19.08.txt.gz'\n",
    "with gzip.open(gzipped_file_path, 'rt', encoding='utf-8') as f_in:\n",
    "    decompressed_data = f_in.read()\n",
    "decompressed_file = io.BytesIO(decompressed_data.encode('utf-8'))\n",
    "model_numberbatch = KeyedVectors.load_word2vec_format(decompressed_file, binary=False)\n",
    "print(f\"NUMBERBATCH: {model_numberbatch.most_similar('seattle')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on one round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess multi-word expressions (e.g. 'New York', 'push-up')\n",
    "def preprocess_word(word, model):\n",
    "  \"\"\"\n",
    "  Preprocess multi-word expressions (MWE) for accomodation by word2vec models.\n",
    "\n",
    "  Args:\n",
    "      word (str): The word to preprocess.\n",
    "      model (gensim.models.word2vec): The word2vec model to check for MWE.\n",
    "\n",
    "  Returns:\n",
    "      str: The preprocessed word.\n",
    "  \"\"\"\n",
    "  mwe = re.sub(r'[-\\s]', '_', word.lower())\n",
    "  \n",
    "  if mwe not in model:\n",
    "      mwe = re.sub(r'_', '', mwe)\n",
    "  \n",
    "  return mwe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract words from ds[i]['words']\n",
    "def guess(model, words):\n",
    "  \"\"\"\n",
    "  Guess the best 4 words to form a group based on word similarity.\n",
    "  \n",
    "  Args:\n",
    "      model (gensim.models.word2vec): The word2vec model to use.\n",
    "      words (list): A list of words to process.\n",
    "  \n",
    "  Returns:\n",
    "      list: A list of the best 4 words to form a group.\n",
    "  \"\"\"\n",
    "  \n",
    "  # Preprocess words for the model, create similarity matrix to find similarities among words\n",
    "  words = [preprocess_word(word, model) for word in words]\n",
    "  similarity_matrix = np.zeros((len(words), len(words)))\n",
    "  for i, word1 in enumerate(words):\n",
    "      for j, word2 in enumerate(words):\n",
    "          if word1 in model and word2 in model:\n",
    "              similarity_matrix[i, j] = model.similarity(word1, word2)\n",
    "          else:\n",
    "              similarity_matrix[i, j] = 0\n",
    "\n",
    "  # Convert the similarity matrix to a DataFrame for easier manipulation\n",
    "  similarity_df = pd.DataFrame(similarity_matrix, index=words, columns=words)\n",
    "  _max = 0\n",
    "  argmax = 0\n",
    "  argword = \"\"\n",
    "  \n",
    "  # Find the word with the highest similarity to the first word\n",
    "  for idx, word in enumerate(words):\n",
    "    if type(similarity_df[word]) is pd.DataFrame:\n",
    "      print(similarity_df[word])\n",
    "    similar_words = similarity_df[word].sort_values(ascending=False)\n",
    "    if similar_words.iloc[1] > _max:\n",
    "      _max = similar_words.iloc[1]\n",
    "      argmax = idx\n",
    "      argword = similar_words.index[1]\n",
    "\n",
    "  # Initialize the build list with the most similar pair of words\n",
    "  build_list = [words[argmax], argword]\n",
    "\n",
    "  # Create a copy of the original words list to avoid modifying it\n",
    "  words_copy = words.copy()\n",
    "  \n",
    "  # Finding the third most similar word to the build list\n",
    "  # Remove the most similar pair from the original words list\n",
    "  for test_word in build_list:\n",
    "    if test_word not in words_copy:\n",
    "      return None\n",
    "    words_copy.remove(test_word)\n",
    "\n",
    "  # Calculate average similarity of remaining words to the build list\n",
    "  sim_list = []\n",
    "  for test_word in words_copy:\n",
    "    similarities = []\n",
    "    for train_word in build_list:\n",
    "        if train_word in model and test_word in model:\n",
    "            similarity = model.similarity(train_word, test_word)\n",
    "            similarities.append(similarity)\n",
    "        else:\n",
    "            similarities.append(0)  # Handle words not in the model\n",
    "    average_similarity = sum(similarities) / len(similarities)\n",
    "    sim_list.append(average_similarity)\n",
    "\n",
    "  # Find the word with the highest average similarity to the build list\n",
    "  index_of_highest_value = sim_list.index(max(sim_list))\n",
    "  build_list.append(words_copy[index_of_highest_value])\n",
    "\n",
    "  # Finding the fourth most similar word to the build list\n",
    "  # Pretty much same code as the third most similar word\n",
    "  words_copy = words.copy()\n",
    "  for test_word in build_list:\n",
    "    if test_word not in words_copy:\n",
    "      return None\n",
    "    words_copy.remove(test_word)\n",
    "\n",
    "  sim_list = []\n",
    "  for test_word in words_copy:\n",
    "    similarities = []\n",
    "    for train_word in build_list:\n",
    "        if train_word in model and test_word in model:\n",
    "            similarity = model.similarity(train_word, test_word)\n",
    "            similarities.append(similarity)\n",
    "        else:\n",
    "            similarities.append(0)  # Handle words not in the model\n",
    "    average_similarity = sum(similarities) / len(similarities)\n",
    "    sim_list.append(average_similarity)\n",
    "\n",
    "  index_of_highest_value = sim_list.index(max(sim_list))\n",
    "  build_list.append(words_copy[index_of_highest_value])\n",
    "\n",
    "  # Return the final list of four words\n",
    "  return build_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_round(guess_list, solution):\n",
    "  \"\"\"\n",
    "  Evaluate the guess list against the solution.\n",
    "\n",
    "  Args:\n",
    "      guess_list (list): The list of guessed words. Should contain 4 entries.\n",
    "      solution (dict): The solution dictionary containing the correct groups.\n",
    "\n",
    "  Returns:\n",
    "      int: The maximum number of correct guesses in any group.\n",
    "  \"\"\"\n",
    "  # right_count evaluates the number of correct guesses in each group\n",
    "  right_count = [0, 0, 0, 0]\n",
    "  \n",
    "  # Check if the guess list is valid\n",
    "  if len(guess_list) != 4:\n",
    "    return None\n",
    "  \n",
    "  # Check if the guess list aligns with a solution\n",
    "  for final_word in guess_list:\n",
    "    for idx, group in enumerate(solution['groups']):\n",
    "      if final_word in group['words']:\n",
    "        right_count[idx] += 1\n",
    "  \n",
    "  # Return the maximum number of correct guesses in any group\n",
    "  # If the guess was all right, then the max will be 4\n",
    "  return max(right_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_google' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[43mmodel_google\u001b[49m, model_glove, model_wiki, model_numberbatch]\n\u001b[0;32m      2\u001b[0m model_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoogle News\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGlove\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWikipedia\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumberbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      3\u001b[0m correct_idx \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_google' is not defined"
     ]
    }
   ],
   "source": [
    "models = [model_google, model_glove, model_wiki, model_numberbatch]\n",
    "model_names = [\"Google News\", \"Glove\", \"Wikipedia\", \"Numberbatch\"]\n",
    "correct_idx = []\n",
    "for idx, model in enumerate(models):\n",
    "  print(f\"======== {model_names[idx]} ========\")\n",
    "  right_list = []\n",
    "  one_away_when = []\n",
    "  for i in range(ds_len):\n",
    "    guess_list = guess(model, ds[i]['words'])\n",
    "    if guess_list is not None:\n",
    "      score = eval_round(guess_list, ds[i]['solution'])\n",
    "      right_list.append(score)\n",
    "      if score == 4 and i not in correct_idx:\n",
    "        correct_idx.append(i)\n",
    "\n",
    "  print(f\"AVERAGE SCORE: {sum(right_list) / len(right_list)}\")\n",
    "  for i in range(1, 5):\n",
    "    print(f\"{i}: {right_list.count(i)}\")\n",
    "  print()\n",
    "print(f\"Number of Games with At Least One Good First Guess: {len(correct_idx)} / {ds_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_matrix(model, words):\n",
    "    words = [preprocess_word(word, model) for word in words]\n",
    "    words = [word for word in words if word in model]\n",
    "    \n",
    "    similarity_matrix = {}\n",
    "    for i, word1 in enumerate(words):\n",
    "        for j, word2 in enumerate(words):\n",
    "            if i < j:  # Avoid redundant computations\n",
    "                similarity_matrix[(word1, word2)] = model.similarity(word1, word2)\n",
    "    return similarity_matrix\n",
    "\n",
    "# Extract words from ds[i]['words'] with fallback guesses\n",
    "# similarity_matrix: precomputed similarity matrix\n",
    "\n",
    "def guess_best_combination(model, words, similarity_matrix=None, lives=4):\n",
    "    if len(words) == 4:\n",
    "        return [list(words) * lives]\n",
    "    words = [preprocess_word(word, model) for word in words]\n",
    "    words = [word for word in words if word in model]\n",
    "\n",
    "    if len(words) < 4 or lives < 1:\n",
    "        return None\n",
    "\n",
    "    if similarity_matrix is None:\n",
    "        similarity_matrix = compute_similarity_matrix(model, words)\n",
    "\n",
    "    all_combinations = list(combinations(words, 4))\n",
    "    scored_combinations = []\n",
    "\n",
    "    for combination in all_combinations:\n",
    "        similarities = []\n",
    "        for i, word1 in enumerate(combination):\n",
    "            for j, word2 in enumerate(combination):\n",
    "                if i < j:\n",
    "                    similarities.append(similarity_matrix.get((word1, word2), similarity_matrix.get((word2, word1), 0)))\n",
    "\n",
    "        average_similarity = np.mean(similarities)\n",
    "        scored_combinations.append((combination, average_similarity))\n",
    "\n",
    "    # Sort combinations by average similarity in descending order\n",
    "    scored_combinations.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Return up to four attempts in descending order of similarity\n",
    "    top_guesses = [list(comb[0]) for comb in scored_combinations[:lives]]\n",
    "    return top_guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['game', 'play', 'movie', 'actor'], ['president', 'movie', 'actor', 'director'], ['play', 'movie', 'actor', 'concert'], ['movie', 'actor', 'director', 'concert']]\n"
     ]
    }
   ],
   "source": [
    "print(guess_best_combination(model_numberbatch, ['hunt', 'check', 'game', 'ford', 'president', 'play', 'car', 'stop', 'oxen', 'block', 'movie', 'actor', 'dam', 'dysentery', 'director', 'concert']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Correct with 0 strikes: 9.0\n",
      "All Correct with 1 strike: 8.1\n",
      "2 Correct Groups - 2 strikes: 2.25\n"
     ]
    }
   ],
   "source": [
    "def calculate_score(num_correct, strikes):\n",
    "    \"\"\"\n",
    "    Calculate the score based on the number of correct guesses and strikes.\n",
    "    \n",
    "    Args:\n",
    "        num_correct (int): The number of correct guesses (0-4).\n",
    "        strikes (int): The number of strikes (0-4).\n",
    "    \n",
    "    Returns:\n",
    "        float: The calculated score.\n",
    "    \"\"\"\n",
    "    # Define multipliers and penalties\n",
    "    multipliers = [1, 2, 3, 3]\n",
    "    penalties = [1.0, 0.9, 0.75, 0.5, 0.25]\n",
    "\n",
    "    # Ensure the number of correct groups is within the valid range\n",
    "    if num_correct > 4:\n",
    "        num_correct = 4\n",
    "\n",
    "    # Calculate the total score\n",
    "    total_score = 0\n",
    "    for i in range(num_correct):\n",
    "        total_score += 1 * multipliers[i] * penalties[strikes]\n",
    "\n",
    "    return np.round(total_score, 2)\n",
    "\n",
    "# Example usage\n",
    "num_correct_1 = 4\n",
    "num_correct_2 = 4\n",
    "num_correct_3 = 2\n",
    "\n",
    "strikes_1 = 0\n",
    "strikes_2 = 1\n",
    "strikes_3 = 2\n",
    "\n",
    "print(\"All Correct with 0 strikes:\", calculate_score(num_correct_1, strikes_1))  # Output: 9.0\n",
    "print(\"All Correct with 1 strike:\", calculate_score(num_correct_2, strikes_2))   # Output: 8.1\n",
    "print(\"2 Correct Groups - 2 strikes:\", calculate_score(num_correct_3, strikes_3)) # Output: 2.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Google News ========\n",
      "AVERAGE SCORE: 0.893312101910828\n",
      "0: 323\n",
      "1: 169\n",
      "2: 76\n",
      "3: 0\n",
      "4: 60\n",
      "Average Total Score: 0.8366242038216564 (Total: 525.4000000000002)\n",
      "\n",
      "======== Glove ========\n",
      "AVERAGE SCORE: 0.8136942675159236\n",
      "0: 335\n",
      "1: 167\n",
      "2: 80\n",
      "3: 0\n",
      "4: 46\n",
      "Average Total Score: 0.6980095541401274 (Total: 438.35)\n",
      "\n",
      "======== Wikipedia ========\n",
      "AVERAGE SCORE: 1.1767515923566878\n",
      "0: 264\n",
      "1: 175\n",
      "2: 96\n",
      "3: 0\n",
      "4: 93\n",
      "Average Total Score: 1.240525477707007 (Total: 779.0500000000003)\n",
      "\n",
      "======== Numberbatch ========\n",
      "GAME 601: 1 correct guesses, 0 lives left\n",
      "GAME 602: 4 correct guesses, 4 lives left\n",
      "GAME 603: 1 correct guesses, 0 lives left\n",
      "GAME 604: 4 correct guesses, 2 lives left\n",
      "GAME 605: 1 correct guesses, 0 lives left\n",
      "GAME 606: 1 correct guesses, 0 lives left\n",
      "GAME 607: 0 correct guesses, 0 lives left\n",
      "GAME 608: 1 correct guesses, 0 lives left\n",
      "GAME 609: 2 correct guesses, 0 lives left\n",
      "GAME 610: 2 correct guesses, 0 lives left\n",
      "GAME 611: 2 correct guesses, 0 lives left\n",
      "GAME 612: 2 correct guesses, 0 lives left\n",
      "GAME 613: 0 correct guesses, 0 lives left\n",
      "GAME 614: 0 correct guesses, 0 lives left\n",
      "GAME 615: 4 correct guesses, 4 lives left\n",
      "GAME 616: 4 correct guesses, 4 lives left\n",
      "GAME 617: 0 correct guesses, 0 lives left\n",
      "GAME 618: 0 correct guesses, 0 lives left\n",
      "GAME 619: 2 correct guesses, 0 lives left\n",
      "GAME 620: 2 correct guesses, 0 lives left\n",
      "GAME 621: 0 correct guesses, 0 lives left\n",
      "GAME 622: 4 correct guesses, 3 lives left\n",
      "GAME 623: 1 correct guesses, 0 lives left\n",
      "GAME 624: 2 correct guesses, 0 lives left\n",
      "GAME 625: 1 correct guesses, 0 lives left\n",
      "GAME 626: 1 correct guesses, 0 lives left\n",
      "GAME 627: 4 correct guesses, 4 lives left\n",
      "AVERAGE SCORE: 1.5318471337579618\n",
      "0: 199\n",
      "1: 170\n",
      "2: 122\n",
      "3: 0\n",
      "4: 137\n",
      "Average Total Score: 1.819187898089172 (Total: 1142.45)\n",
      "\n",
      "Number of Games with At Least One Complete Solve: 175 / 628\n"
     ]
    }
   ],
   "source": [
    "models = [model_google, model_glove, model_wiki, model_numberbatch]\n",
    "model_names = [\"Google News\", \"Glove\", \"Wikipedia\", \"Numberbatch\"]\n",
    "correct_idx = []\n",
    "multiplier = {4: 1.0, 3: 0.9, 2: 0.75, 1: 0.5, 0: 0.25}\n",
    "\n",
    "# Iterate through each model and evaluate the guesses\n",
    "for idx, model in enumerate(models):\n",
    "  print(f\"======== {model_names[idx]} ========\")\n",
    "  right_list = []\n",
    "  correct_guesses = []\n",
    "  total_scores = []\n",
    "  one_away_when = []\n",
    "  for i in range(len(ds)):\n",
    "    #print(\"I:\", i)\n",
    "    lives = 4\n",
    "    correct_count = 0\n",
    "    total_score = 0\n",
    "    options = ds[i]['words']\n",
    "    while lives > 0 and len(options) > 0:\n",
    "      #print(\"LEN:\", len(options))\n",
    "      guess_list = guess_best_combination(model, options, lives=lives)\n",
    "      #print(\"GUESS:\", guess_list)\n",
    "      if guess_list is None:\n",
    "        lives -= 1\n",
    "        continue\n",
    "      if guess_list is not None:\n",
    "        for guess in guess_list:\n",
    "          score = eval_round(guess, ds[i]['solution'])\n",
    "          if score == 4:\n",
    "            correct_count += 1\n",
    "            right_list.append(score)\n",
    "            options = [item for item in options if item not in guess]\n",
    "            if len(options) == 4:\n",
    "              correct_count += 1\n",
    "              options = []\n",
    "            break\n",
    "          lives -= 1\n",
    "          if guess == guess_list[-1] or lives == 0:\n",
    "            right_list.append(score)\n",
    "            break\n",
    "    correct_guesses.append(correct_count)\n",
    "    if model == model_numberbatch and i > 600:\n",
    "      print(f\"GAME {i}: {correct_count} correct guesses, {lives} lives left\")\n",
    "    total_scores.append(calculate_score(correct_count, 4 - lives))\n",
    "    if correct_count == 4 and i not in correct_idx:\n",
    "      correct_idx.append(i)\n",
    "\n",
    "  print(f\"AVERAGE SCORE: {sum(correct_guesses) / len(correct_guesses)}\")\n",
    "  for i in range(0, 5):\n",
    "    print(f\"{i}: {correct_guesses.count(i)}\")\n",
    "  print(f\"Average Total Score: {sum(total_scores) / len(total_scores)} (Total: {sum(total_scores)})\")\n",
    "  print()\n",
    "print(f\"Number of Games with At Least One Complete Solve: {len(correct_idx)} / {ds_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyedVectors<vector_size=300, 3000000 keys> ['snow', 'level', 'shift', 'kayak', 'heat', 'tab', 'bucks', 'return', 'jazz', 'hail', 'option', 'rain', 'sleet', 'racecar', 'mom', 'nets']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['snow', 'hail', 'rain', 'sleet'],\n",
       " ['snow', 'heat', 'rain', 'sleet'],\n",
       " ['snow', 'jazz', 'rain', 'sleet'],\n",
       " ['snow', 'kayak', 'rain', 'sleet']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model_google, ds[0]['words'])\n",
    "guess_best_combination(model_google, ds[0]['words'], lives=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def aggregate_rankings(models, weights, words, lives=4):\n",
    "    ranking_scores = defaultdict(float)\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model_guesses = guess_best_combination(model, words, similarity_matrix=None, lives=lives)\n",
    "        if model_guesses:\n",
    "            for rank, guess in enumerate(model_guesses):\n",
    "                ranking_scores[tuple(guess)] += weights[name] / (rank + 1)  # Convert list to tuple\n",
    "\n",
    "    # Sort final ranked list\n",
    "    sorted_guesses = sorted(ranking_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [list(guess[0]) for guess in sorted_guesses[:lives]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('carrots', 0.7685447931289673),\n",
       " ('proverbial_carrot', 0.5643057823181152),\n",
       " ('Carrot', 0.48995766043663025),\n",
       " ('celery', 0.47531840205192566),\n",
       " ('dangling_carrot', 0.47465410828590393),\n",
       " ('Coarsely_grate', 0.47062399983406067),\n",
       " ('carrot_dangling', 0.4619136154651642),\n",
       " ('broccoli', 0.45493656396865845),\n",
       " ('raisin_salad', 0.45256876945495605),\n",
       " ('shredded_zucchini', 0.4489986002445221)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_google.most_similar('carrot', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Aggregate Model Evaluation ========\n",
      "AVERAGE SCORE: 1.5047770700636942\n",
      "0: 193\n",
      "1: 189\n",
      "2: 114\n",
      "3: 0\n",
      "4: 132\n",
      "Average Total Score: 1.7828025477707008 (Total: 1119.6000000000001)\n",
      "\n",
      "Number of Games with At Least One Complete Solve: 132 / 628\n"
     ]
    }
   ],
   "source": [
    "weights_dict = {\n",
    "    \"google\": 0.8366 / (0.8366 + 0.6980 + 1.2405 + 1.8192),\n",
    "    \"glove\": 0.6980 / (0.8366 + 0.6980 + 1.2405 + 1.8192),\n",
    "    \"wiki\": 1.2405 / (0.8366 + 0.6980 + 1.2405 + 1.8192),\n",
    "    \"numberbatch\": 1.8192 / (0.8366 + 0.6980 + 1.2405 + 1.8192),\n",
    "}\n",
    "\n",
    "models_dict = {\n",
    "    \"google\": model_google,\n",
    "    \"glove\": model_glove,\n",
    "    \"wiki\": model_wiki,\n",
    "    \"numberbatch\": model_numberbatch\n",
    "}\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def evaluate_aggregate_rankings(models, weights, dataset):\n",
    "    correct_idx = []\n",
    "    correct_guesses = []\n",
    "    total_scores = []\n",
    "    ds_len = len(dataset)\n",
    "    \n",
    "    print(\"======== Aggregate Model Evaluation ========\")\n",
    "    \n",
    "    for i in range(ds_len):\n",
    "        lives = 4\n",
    "        correct_count = 0\n",
    "        total_score = 0\n",
    "        options = dataset[i]['words']\n",
    "        \n",
    "        while lives > 0 and len(options) > 0:\n",
    "            guess_list = aggregate_rankings(models, weights, options, lives=lives)\n",
    "            \n",
    "            if not guess_list:\n",
    "                lives -= 1\n",
    "                continue\n",
    "            \n",
    "            for guess in guess_list:\n",
    "                score = eval_round(guess, dataset[i]['solution'])\n",
    "                if score == 4:\n",
    "                    correct_count += 1\n",
    "                    options = [item for item in options if item not in guess]\n",
    "                    if len(options) == 4:\n",
    "                        correct_count += 1\n",
    "                        options = []\n",
    "                    break\n",
    "                \n",
    "                lives -= 1\n",
    "                if guess == guess_list[-1] or lives == 0:\n",
    "                    break\n",
    "        \n",
    "        correct_guesses.append(correct_count)\n",
    "        total_scores.append(calculate_score(correct_count, 4 - lives))\n",
    "        \n",
    "        if correct_count == 4 and i not in correct_idx:\n",
    "            correct_idx.append(i)\n",
    "    \n",
    "    print(f\"AVERAGE SCORE: {sum(correct_guesses) / len(correct_guesses)}\")\n",
    "    for i in range(0, 5):\n",
    "        print(f\"{i}: {correct_guesses.count(i)}\")\n",
    "    print(f\"Average Total Score: {sum(total_scores) / len(total_scores)} (Total: {sum(total_scores)})\")\n",
    "    print()\n",
    "    print(f\"Number of Games with At Least One Complete Solve: {len(correct_idx)} / {ds_len}\")\n",
    "\n",
    "# Call the evaluation function\n",
    "evaluate_aggregate_rankings(models_dict, weights_dict, ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_round(guess_list, solution):\n",
    "  \"\"\"\n",
    "  Evaluate the guess list against the solution.\n",
    "\n",
    "  Args:\n",
    "      guess_list (list): The list of guessed words. Should contain 4 entries.\n",
    "      solution (dict): The solution dictionary containing the correct groups.\n",
    "\n",
    "  Returns:\n",
    "      int: The maximum number of correct guesses in any group.\n",
    "  \"\"\"\n",
    "  # right_count evaluates the number of correct guesses in each group\n",
    "  right_count = [0, 0, 0, 0]\n",
    "  \n",
    "  # Check if the guess list is valid\n",
    "  if len(guess_list) != 4:\n",
    "    return None\n",
    "  \n",
    "  # Check if the guess list aligns with a solution\n",
    "  for final_word in guess_list:\n",
    "    for idx, group in enumerate(solution['groups']):\n",
    "      if final_word in group['words']:\n",
    "        right_count[idx] += 1\n",
    "  \n",
    "  # Return the maximum number of correct guesses in any group\n",
    "  # If the guess was all right, then the max will be 4\n",
    "  return max(right_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "description = \"You are an assistant configured to solve the New York Times Connections Word game.\"\n",
    "init_prompt = \"\"\"\n",
    "You are an assistant configured to solve the New York Times Connections Word game.\n",
    "Out of the given words, please return a group of 4 words that you are most confident are related to each other.\n",
    "Please output your response in a JSON format with the following structure:\n",
    "{\n",
    "  \"words\": [\"word1\", \"word2\", \"word3\", \"word4\"],\n",
    "  \"reason\": \"Your reasoning here.\"\n",
    "}\n",
    "\n",
    "You may assume the following:\n",
    "1. The provided list of words will always be a multiple of four, and a group of four words will always exist.\n",
    "2. Every word in the provided list is part of a group of four words, but you only need to make one guess.\n",
    "3. There will never be a \"miscellaneous\" group, and no word will be part of more than one group.\n",
    "4. A red herring category may be present, where some words appear to be related but are not part of the correct group.\n",
    "\n",
    "Please give your answer in a JSON format and do not provide any other text. Your words to choose from are as follows:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_round(['foot', 'league', 'mile', 'yard'], ds[1]['solution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game 1: ['snow', 'level', 'shift', 'kayak', 'heat', 'tab', 'bucks', 'return', 'jazz', 'hail', 'option', 'rain', 'sleet', 'racecar', 'mom', 'nets']\n",
      "{'words': ['snow', 'hail', 'sleet', 'rain'], 'reason': 'These words are all types of precipitation.'}\n",
      "['hail', 'rain', 'sleet', 'snow'] 4\n",
      "Correct response!\n",
      "{'words': ['kayak', 'racecar', 'mom', 'level'], 'reason': 'These words are palindromes; they read the same backward as forward.'}\n",
      "['kayak', 'level', 'mom', 'racecar'] 4\n",
      "Correct response!\n",
      "{'words': ['jazz', 'nets', 'bucks', 'heat'], 'reason': 'These are all names of professional basketball teams in the NBA: Utah Jazz, Brooklyn Nets, Milwaukee Bucks, and Miami Heat.'}\n",
      "['bucks', 'heat', 'jazz', 'nets'] 4\n",
      "Correct response!\n",
      "{'words': ['shift', 'tab', 'return', 'option'], 'reason': 'These words are all keys on a computer keyboard.'}\n",
      "['option', 'return', 'shift', 'tab'] 4\n",
      "Correct response!\n",
      "Game 2: ['pump', 'foot', 'time', 'sea', 'league', 'loafer', 'why', 'us', 'boot', 'yard', 'people', 'are', 'mile', 'sneaker', 'queue', 'essence']\n",
      "{'words': ['pump', 'loafer', 'boot', 'sneaker'], 'reason': 'These words are all types of footwear.'}\n",
      "['boot', 'loafer', 'pump', 'sneaker'] 4\n",
      "Correct response!\n",
      "{'words': ['foot', 'yard', 'mile', 'league'], 'reason': 'These words are all units of measurement.'}\n",
      "['foot', 'league', 'mile', 'yard'] 4\n",
      "Correct response!\n",
      "{'words': ['time', 'sea', 'queue', 'essence'], 'reason': \"These words relate to expressions involving the concept of waiting: 'time' is often equated to the essence; 'queue' is a line indicating waiting; 'sea' is sometimes part of the phrase 'waiting at sea'.\"}\n",
      "['essence', 'queue', 'sea', 'time'] 2\n",
      "Incorrect.\n",
      "{'words': ['people', 'us', 'are', 'why'], 'reason': \"These words can be related as they are all pronouns or relate to the concept of questioning and people: 'people', 'us', 'are' (which could be interpreted as a formal verb relating to people), and 'why' (as a question often associated with people). This form of grouping links them to communication or language elements involving people.\"}\n",
      "['are', 'people', 'us', 'why'] 2\n",
      "Incorrect.\n",
      "{'words': ['sea', 'people', 'us', 'are'], 'reason': \"These words can be related to the concept of a group or collective. 'Sea' as in large groups (e.g., a sea of people), 'people' as in a group of individuals, 'us' as in a collective pronoun, and 'are' as a verb used in plural sentences, often related to groups.\"}\n",
      "['are', 'people', 'sea', 'us'] 2\n",
      "Incorrect.\n",
      "{'words': ['time', 'essence', 'us', 'sea'], 'reason': \"The words 'time' and 'essence' are often grouped together in the common phrase 'time is of the essence', suggesting a possible category alignment. Given previous incorrect and successful guesses, this combination has not yet been tried and may form a valid group together with 'us' and 'sea' based on common expressions or categorizations.\"}\n",
      "['essence', 'sea', 'time', 'us'] 3\n",
      "Incorrect. One away...\n",
      "Game 3: ['amigo', 'mouth', 'lab', 'stooge', 'wolf', 'king', 'nose', 'chow', 'tenor', 'pom', 'scarf', 'eye', 'pit', 'gobble', 'peke', 'cheek']\n",
      "{'words': ['mouth', 'nose', 'eye', 'cheek'], 'reason': 'These words are all parts of the face.'}\n",
      "['cheek', 'eye', 'mouth', 'nose'] 4\n",
      "Correct response!\n",
      "{'words': ['amigo', 'stooge', 'king', 'tenor'], 'reason': \"These words are associated with the word 'Three': Three Amigos, Three Stooges, Three Kings, and Three Tenors.\"}\n",
      "['amigo', 'king', 'stooge', 'tenor'] 4\n",
      "Correct response!\n",
      "{'words': ['wolf', 'chow', 'pom', 'peke'], 'reason': 'These words are all breeds of dogs.'}\n",
      "['chow', 'peke', 'pom', 'wolf'] 2\n",
      "Incorrect.\n",
      "{'words': ['lab', 'wolf', 'chow', 'pit'], 'reason': 'These words are all types of dogs: Labrador (lab), Wolf, Chow Chow (chow), and Pit Bull Terrier (pit).'}\n",
      "['chow', 'lab', 'pit', 'wolf'] 2\n",
      "Incorrect.\n",
      "{'words': ['scarf', 'pit', 'gobble', 'lab'], 'reason': \"These words are related through themes of consumption or cover: 'scarf' and 'gobble' are related to eating, while 'pit' (as in a peach pit) and 'lab' (as in laboratory experiments involving chemical reactions that can involve consumption) loosely fit this theme, although they are more of a stretch, it's aimed at drawing away from previous incorrect animal guesses.\"}\n",
      "['gobble', 'lab', 'pit', 'scarf'] 2\n",
      "Incorrect.\n",
      "{'words': ['scarf', 'gobble', 'chow', 'pit'], 'reason': \"These words are related to eating: 'scarf', 'gobble', and 'chow' refer to eating quickly or messily, while 'pit' can refer to a type of eating establishment (as in 'barbecue pit').\"}\n",
      "['chow', 'gobble', 'pit', 'scarf'] 3\n",
      "Incorrect. One away...\n",
      "Game 4: ['dust', 'cats', 'spider', 'carousel', 'puma', 'iron', 'nike', 'mop', 'chicago', 'sweep', 'super', 'bat', 'reebok', 'cabaret', 'vacuum', 'adidas']\n",
      "{'words': ['puma', 'nike', 'reebok', 'adidas'], 'reason': 'These words are related because they are all well-known brands in the athletic wear and sports gear industry.'}\n",
      "['adidas', 'nike', 'puma', 'reebok'] 4\n",
      "Correct response!\n",
      "{'words': ['dust', 'mop', 'sweep', 'vacuum'], 'reason': \"These words are related to cleaning. 'Dust,' 'mop,' 'sweep,' and 'vacuum' are all associated with removing dirt or maintaining cleanliness.\"}\n",
      "['dust', 'mop', 'sweep', 'vacuum'] 4\n",
      "Correct response!\n",
      "{'words': ['spider', 'carousel', 'iron', 'bat'], 'reason': \"These words can all be associated with 'types of things' found in amusement parks or superhero contexts. Spider and Bat relate to superhero names (Spider-Man, Batman), and Carousel and Iron (Iron Man) can also fit thematically with superhero and amusement themes in pop culture.\"}\n",
      "['bat', 'carousel', 'iron', 'spider'] 3\n",
      "Incorrect. One away...\n",
      "{'words': ['cats', 'chicago', 'super', 'cabaret'], 'reason': \"These words are related to Broadway or theater shows: 'Cats' (musical), 'Chicago' (musical), 'Super' (could relate to Superstars on Broadway), and 'Cabaret' (musical).\"}\n",
      "['cabaret', 'cats', 'chicago', 'super'] 3\n",
      "Incorrect. One away...\n",
      "{'words': ['bat', 'spider', 'super', 'iron'], 'reason': \"These words are all related to superheroes or superhero-related concepts. 'Bat' is associated with Batman, 'spider' with Spider-Man, 'super' with Superman, and 'iron' with Iron Man.\"}\n",
      "['bat', 'iron', 'spider', 'super'] 4\n",
      "Correct response!\n",
      "{'words': ['cats', 'carousel', 'chicago', 'cabaret'], 'reason': \"The words 'cats', 'carousel', 'chicago', and 'cabaret' seem to be related to theater and musicals, possibly referencing famous shows or themes in theaters. However, previous incorrect guess suggests that this might not be their relation, possibly pointing to another subtle theme they represent.\"}\n",
      "['cabaret', 'carousel', 'cats', 'chicago'] 4\n",
      "Correct response!\n",
      "Game 5: ['mustard', 'tartar', 'plum', 'blue', 'green', 'prime', 'glum', 'relish', 'down', 'peacock', 'ketchup', 'low', 'hulu', 'scarlet', 'mayo', 'netflix']\n",
      "{'words': ['mustard', 'ketchup', 'mayo', 'relish'], 'reason': 'These words are all types of condiments often used in food preparation or as toppings.'}\n",
      "['ketchup', 'mayo', 'mustard', 'relish'] 3\n",
      "Incorrect. One away...\n",
      "{'words': ['hulu', 'netflix', 'prime', 'peacock'], 'reason': 'These words are all names of popular streaming services.'}\n",
      "['hulu', 'netflix', 'peacock', 'prime'] 4\n",
      "Correct response!\n",
      "{'words': ['plum', 'blue', 'green', 'scarlet'], 'reason': 'These words are all colors. Plum is a shade of purple, blue and green are primary and secondary colors, and scarlet is a shade of red.'}\n",
      "['blue', 'green', 'plum', 'scarlet'] 3\n",
      "Incorrect. One away...\n",
      "{'words': ['tartar', 'ketchup', 'low', 'down'], 'reason': 'These words are related as they all refer to moods or expressions that can be interpreted as negative or low-key, since ‘tartar’ is associated with sour expressions, ‘low’ and ‘down’ with an emotional state or level, and ketchup could be considered an emotional red herring alongside tartar.'}\n",
      "['down', 'ketchup', 'low', 'tartar'] 2\n",
      "Incorrect.\n",
      "{'words': ['glum', 'low', 'blue', 'down'], 'reason': 'These words are all synonyms or related to feelings or states of sadness or decreased energy.'}\n",
      "['blue', 'down', 'glum', 'low'] 4\n",
      "Correct response!\n",
      "{'words': ['mustard', 'tartar', 'relish', 'ketchup'], 'reason': 'These words are all condiments commonly used as sauces or accompaniments with food.'}\n",
      "['ketchup', 'mustard', 'relish', 'tartar'] 3\n",
      "Incorrect. One away...\n",
      "Game 6: ['wonder', 'future', 'baby', 'go', 'sin', 'chance', 'royal', 'ice cube', 'midnight', 'jail', 'sea', 'powder', 'q-tip', 'sister', 'boardwalk', 'common']\n",
      "{'words': ['wonder', 'future', 'chance', 'midnight'], 'reason': \"These words are all titles of songs by popular artists. 'Wonder' by Shawn Mendes, 'Future' by Madonna, 'Chance' by Sia, and 'Midnight' by Coldplay.\"}\n",
      "['chance', 'future', 'midnight', 'wonder'] 1\n",
      "Incorrect.\n",
      "{'words': ['sea', 'ice cube', 'powder', 'boardwalk'], 'reason': \"These words are related to the beach or elements found at the beach: 'sea' for the ocean, 'ice cube' can refer to beach coolers, 'powder' for sandy texture, and 'boardwalk' being a common feature near beaches.\"}\n",
      "['boardwalk', 'ice cube', 'powder', 'sea'] 1\n",
      "Incorrect.\n",
      "{'words': ['baby', 'royal', 'common', 'sister'], 'reason': \"Each word is commonly used as a title for a 'sister': Baby sister, Royal sister, Common sister, and Sister in general.\"}\n",
      "['baby', 'common', 'royal', 'sister'] 2\n",
      "Incorrect.\n",
      "{'words': ['go', 'jail', 'sin', 'q-tip'], 'reason': \"These words can be associated with actions or warnings: 'Go' is an action command, 'Jail' can be a warning or destination from Monopoly, 'Sin' is often a warning in religious contexts, and 'Q-tip' can be a warning label to avoid sticking them in ears.\"}\n",
      "['go', 'jail', 'q-tip', 'sin'] 2\n",
      "Incorrect.\n",
      "Game 7: ['john', 'cub', 'star', 'silver', 'knee', 'throne', 'joey', 'jelly', 'calf', 'ankle', 'cray', 'head', 'shin', 'can', 'kid', 'thigh']\n",
      "{'words': ['knee', 'ankle', 'shin', 'thigh'], 'reason': 'These words are all related because they are parts of the leg in human anatomy.'}\n",
      "['ankle', 'knee', 'shin', 'thigh'] 4\n",
      "Correct response!\n",
      "{'words': ['cub', 'joey', 'calf', 'kid'], 'reason': 'All these words refer to young or juvenile names of animals: cub (young bear), joey (young kangaroo), calf (young cow or elephant), and kid (young goat).'}\n",
      "['calf', 'cub', 'joey', 'kid'] 4\n",
      "Correct response!\n",
      "{'words': ['john', 'silver', 'jelly', 'can'], 'reason': \"These words are related to metal or containers: 'silver' is a metal, 'jelly' can be in a jar or can, 'john' as in 'John Silver' who is known for a silver metal (related to containers), and 'can' which is a type of container.\"}\n",
      "['can', 'jelly', 'john', 'silver'] 2\n",
      "Incorrect.\n",
      "{'words': ['john', 'star', 'silver', 'head'], 'reason': \"These words are related to the theme of pirates, specifically terms that can be associated with the story of 'Treasure Island' – Captain John Silver, and terms like 'star' and 'head' relating to pirate language and maps.\"}\n",
      "['head', 'john', 'silver', 'star'] 2\n",
      "Incorrect.\n",
      "{'words': ['head', 'star', 'throne', 'cray'], 'reason': \"These words are related to symbols or parts that are often associated with significance: head and throne signify leadership or a central position, while star is often symbolic of guidance or high status, and cray could refer to 'crazy' which is often used to describe something intense or significant.\"}\n",
      "['cray', 'head', 'star', 'throne'] 2\n",
      "Incorrect.\n",
      "{'words': ['can', 'head', 'john', 'throne'], 'reason': \"The word 'can' can refer to something head-shaped or cylindrical, 'head' can refer to the top or leader, 'john' could refer to a throne in the context of slang for a toilet, and 'throne' itself is a seat of power, such as in a bathroom setting.\"}\n",
      "['can', 'head', 'john', 'throne'] 4\n",
      "Correct response!\n",
      "{'words': ['star', 'silver', 'cray', 'jelly'], 'reason': \"These words seem to form a coherent group where each word can be used informally or in slang contexts. 'Star' and 'Cray' (short for 'crazy') can be used as slang, while 'Silver' and 'Jelly' can also fit into informal contexts. Since other possibilities involving these words have been tested without success, this combination is likely related in another nuanced way.\"}\n",
      "['cray', 'jelly', 'silver', 'star'] 4\n",
      "Correct response!\n",
      "Game 8: ['locksmith', 'fire truck', 'king', 'piano', 'chess', 'ruby', 'florida', 'twin', 'cherry', 'queen', 'stop sign', 'go', 'checkers', 'cryptography', 'full', 'backgammon']\n",
      "{'words': ['chess', 'king', 'queen', 'checkers'], 'reason': 'These words are all related to board games. Chess is a board game that involves a King and a Queen as pieces, and checkers is another type of board game.'}\n",
      "['checkers', 'chess', 'king', 'queen'] 2\n",
      "Incorrect.\n",
      "{'words': ['locksmith', 'ruby', 'cherry', 'fire truck'], 'reason': \"These words relate to different objects or entities that are associated with color, particularly red: a 'ruby' is a red gemstone, a 'cherry' is a fruit often associated with the color red, 'fire truck' is commonly red, and 'locksmith' has 'lock' which could point to metal's sometimes rusty red hue.\"}\n",
      "['cherry', 'fire truck', 'locksmith', 'ruby'] 3\n",
      "Incorrect. One away...\n",
      "{'words': ['piano', 'cherry', 'twin', 'ruby'], 'reason': 'Except for common known group categories based on the previous incorrect guesses, these words are associated with objects that can be described as being in a pair or duplicate: twin being the obvious one, a pair of cherries, a pair of pianos (e.g., grand piano, upright piano) and rubies can come in matching pairs in jewelry.'}\n",
      "['cherry', 'piano', 'ruby', 'twin'] 2\n",
      "Incorrect.\n",
      "{'words': ['fire truck', 'chess', 'stop sign', 'go'], 'reason': \"These words are related to traffic and game instructions: 'fire truck', 'stop sign', and 'go' are associated with roads and direction, while 'chess' uses 'go' as a term for a move.\"}\n",
      "['chess', 'fire truck', 'go', 'stop sign'] 2\n",
      "Incorrect.\n",
      "Game 9: ['squash', 'tee', 'carrot', 'ant', 'tank', 'corn', 'cricket', 'mantis', 'polo', 'onion', 'beetle', 'beet', 'cami', 'termite', 'halter', 'fencing']\n",
      "{'words': ['ant', 'mantis', 'beetle', 'termite'], 'reason': 'These are all types of insects.'}\n",
      "['ant', 'beetle', 'mantis', 'termite'] 4\n",
      "Correct response!\n",
      "{'words': ['tee', 'cricket', 'polo', 'fencing'], 'reason': \"These four words are all related to sports: 'tee' is used in golf, 'cricket' is a sport, 'polo' is another sport, and 'fencing' is a combat sport.\"}\n",
      "['cricket', 'fencing', 'polo', 'tee'] 3\n",
      "Incorrect. One away...\n",
      "{'words': ['carrot', 'onion', 'beet', 'corn'], 'reason': 'These words are related as they are all types of vegetables.'}\n",
      "['beet', 'carrot', 'corn', 'onion'] 4\n",
      "Correct response!\n",
      "{'words': ['tank', 'cami', 'halter', 'tee'], 'reason': 'These words are all types of clothing items, specifically tops or sleeveless shirts.'}\n",
      "['cami', 'halter', 'tank', 'tee'] 4\n",
      "Correct response!\n",
      "{'words': ['squash', 'cricket', 'polo', 'fencing'], 'reason': 'These words are all names of sports or games.'}\n",
      "['cricket', 'fencing', 'polo', 'squash'] 4\n",
      "Correct response!\n",
      "Game 10: ['twins', 'turkey', 'goat', 'kiwi', 'scales', 'fish', 'jordan', 'jay', 'orange', 'georgia', 'date', 'crane', 'togo', 'swallow', 'lemon', 'chad']\n",
      "{'words': ['kiwi', 'turkey', 'goat', 'crane'], 'reason': 'These are all names of birds: Kiwi, Turkey, Goat (Mountain Goat, but also can relate to birds in specific contexts), and Crane.'}\n",
      "['crane', 'goat', 'kiwi', 'turkey'] 2\n",
      "Incorrect.\n",
      "{'words': ['jay', 'swallow', 'crane', 'turkey'], 'reason': 'These are all types of birds.'}\n",
      "['crane', 'jay', 'swallow', 'turkey'] 4\n",
      "Correct response!\n",
      "{'words': ['orange', 'georgia', 'jordan', 'chad'], 'reason': 'These are all names of geographical locations: Georgia, Jordan, and Chad are countries, and Orange is a region in France.'}\n",
      "['chad', 'georgia', 'jordan', 'orange'] 3\n",
      "Incorrect. One away...\n",
      "{'words': ['twins', 'scales', 'fish', 'date'], 'reason': 'These words are related to the zodiac signs. Twins refers to Gemini, scales to Libra, fish to Pisces, and date to the timestamp for each of these signs.'}\n",
      "['date', 'fish', 'scales', 'twins'] 3\n",
      "Incorrect. One away...\n",
      "{'words': ['date', 'orange', 'lemon', 'kiwi'], 'reason': 'These words are all types of fruit.'}\n",
      "['date', 'kiwi', 'lemon', 'orange'] 4\n",
      "Correct response!\n",
      "{'words': ['georgia', 'jordan', 'togo', 'chad'], 'reason': 'These words are all names of countries.'}\n",
      "['chad', 'georgia', 'jordan', 'togo'] 4\n",
      "Correct response!\n",
      "{'words': ['twins', 'goat', 'scales', 'fish'], 'reason': 'These words represent the signs of the zodiac: Gemini (twins), Capricorn (goat), Libra (scales), Pisces (fish).'}\n",
      "['fish', 'goat', 'scales', 'twins'] 4\n",
      "Correct response!\n"
     ]
    }
   ],
   "source": [
    "for game in range(10): # currently looping first 10 games\n",
    "  current_list = ds[game]['words'].copy()\n",
    "  print(f\"Game {game+1}: {current_list}\")\n",
    "  responses = []\n",
    "  response_acc = []\n",
    "  lives = 4\n",
    "  invalid_lives = 3\n",
    "  client = OpenAI(api_key=api_key)\n",
    "  description = \"You are an assistant configured to solve the New York Times Connections Word game.\"\n",
    "  init_prompt = \"\"\"\n",
    "  You are an assistant configured to solve the New York Times Connections Word game.\n",
    "  Out of the given words, please return a group of 4 words that you are most confident are related to each other.\n",
    "  Please output your response in a JSON format with the following structure:\n",
    "  {\n",
    "    \"words\": [\"word1\", \"word2\", \"word3\", \"word4\"],\n",
    "    \"reason\": \"Your reasoning here.\"\n",
    "  }\n",
    "\n",
    "  You may assume the following:\n",
    "  1. The provided list of words will always be a multiple of four, and a group of four words will always exist.\n",
    "  2. Every word in the provided list is part of a group of four words, but you only need to make one guess.\n",
    "  3. There will never be a \"miscellaneous\" group, and no word will be part of more than one group.\n",
    "  4. A red herring category may be present, where some words appear to be related but are not part of the correct group.\n",
    "\n",
    "  Please give your answer in a JSON format and do not provide any other text. Your words to choose from are as follows:\n",
    "  \"\"\"\n",
    "\n",
    "  # loop through game until we get a complete game or game over (run out of 4 lives, or make 3 invalid guesses)\n",
    "  while len(current_list) > 0 and lives > 0 and invalid_lives > 0:\n",
    "    words = \", \".join(current_list)\n",
    "    \n",
    "    # display previous guesses, if any\n",
    "    if len(responses) > 0:\n",
    "      addl_prompt = \"\"\"\n",
    "      \n",
    "      In addition, below is a list of previous guesses you made, and whether it's a correct, incorrect, or invalid guess.\n",
    "      Please use these to help inform your decision, and remember to only choose words from the words list provided above.\n",
    "      Do not repeat any of your previous guesses.\n",
    "      Your previous guesses:\n",
    "      \"\"\"\n",
    "      for i, prevs in enumerate(responses):\n",
    "        addl_prompt += ', '.join(prevs)\n",
    "        if response_acc[i] == 1:\n",
    "          addl_prompt += \" (correct)\\n\"\n",
    "        elif response_acc[i] == 0:\n",
    "          addl_prompt += \" (incorrect)\\n\"\n",
    "        else:\n",
    "          addl_prompt += \" (invalid)\\n\"\n",
    "    else:\n",
    "      addl_prompt = \"\"\n",
    "    prompt = init_prompt + words + addl_prompt\n",
    "    # print(prompt)\n",
    "    \n",
    "    # get response from OpenAI API\n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt-4o\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": description},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ],\n",
    "      max_completion_tokens=500,\n",
    "      response_format={ \"type\": \"json_object\" }\n",
    "    )\n",
    "    response = response.choices[0].message.content\n",
    "    response = json.loads(response)\n",
    "    print(response)\n",
    "    \n",
    "    # standardize response: lower case, sort alphabetically\n",
    "    response['words'] = sorted([word.lower() for word in response['words']])\n",
    "    \n",
    "    # Check for invalid responses\n",
    "    # Check if all words in guess are in current list\n",
    "    invalid = False\n",
    "    for word in response['words']:\n",
    "      if word not in current_list:\n",
    "        print(\"Invalid response: made up a word.\") # debug\n",
    "        responses.append(response['words'])\n",
    "        response_acc.append(-1)\n",
    "        invalid_lives -= 1\n",
    "        invalid = True\n",
    "    \n",
    "    # Check if the response is a duplicate of previous responses, or if there's not exactly 4 unique words\n",
    "    if sorted(response['words']) in responses or len(set(response['words'])) != 4:\n",
    "      print(\"Invalid response: duplicate or not 4 unique words.\") # debug\n",
    "      responses.append(response['words'])\n",
    "      response_acc.append(-1)\n",
    "      invalid_lives -= 1\n",
    "      invalid = True\n",
    "    \n",
    "    if invalid:\n",
    "      continue\n",
    "    \n",
    "    # valid guess, get score\n",
    "    responses.append(response['words'])\n",
    "    score = eval_round(response['words'], ds[game]['solution'])\n",
    "    if score == 4:\n",
    "      print(\"Correct response!\") # debug\n",
    "      response_acc.append(1)\n",
    "      current_list = [item for item in current_list if item not in response['words']]\n",
    "      continue\n",
    "    else:\n",
    "      print(\"Incorrect.\" + (\" One away...\" if score == 3 else \"\")) # debug\n",
    "      response_acc.append(0)\n",
    "      lives -= 1\n",
    "      continue\n",
    "  \n",
    "  # Your tasks:\n",
    "  # 1. Save the results of the responses to the JSON format\n",
    "  # 2. Experiment with the different responses/shots (zero-shot, one-shot, few-shot)\n",
    "  # 3. Once you're happy with the first two, run it on the entire dataset and save the JSON data of each game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'groups': [{'words': ['pump', 'loafer', 'boot', 'sneaker'],\n",
       "   'reason': 'footwear'},\n",
       "  {'words': ['sea', 'why', 'are', 'queue'], 'reason': 'letter homophones'},\n",
       "  {'words': ['time', 'us', 'people', 'essence'], 'reason': 'magazines'},\n",
       "  {'words': ['foot', 'league', 'yard', 'mile'], 'reason': 'units of length'}]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[1]['solution']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['extra',\n",
       " 'ball',\n",
       " 'won',\n",
       " 'mug',\n",
       " 'pin',\n",
       " 'copy',\n",
       " 'too',\n",
       " 'tee',\n",
       " 'ate',\n",
       " 'alley',\n",
       " 'pen',\n",
       " 'backup',\n",
       " 'spare',\n",
       " 'tote',\n",
       " 'for',\n",
       " 'lane']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[100]['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_round(responses[0], ds[0]['solution'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "Due: 6 March 2025\n",
    "\n",
    "Group 1:\n",
    "1. Write some code to try and better save attributes of results!\n",
    "    * Ex: What are the guesses that are being made? What does each game look like?\n",
    "    * I recommend saving the results as a JSON for organization, but feel free to decide how you'd like to save your results.\n",
    "2. Generate a graph of some kind that can give some insights!\n",
    "    * E.g. What kinds of groups are most commonly solved? What do you see with groups that are solved? What kinds of group difficulties are solved most often?\n",
    "\n",
    "Group 2:\n",
    "* Devise a better guessing algorithm, and implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('y', 3474), ('sede', 2225), ('tery', 2195), ('fluous', 2087), ('h', 1995), ('ior', 1873), ('ing', 1808), ('e', 1802), ('ed', 1764), ('cilious', 1741)]\n"
     ]
    }
   ],
   "source": [
    "# call datamuse api to find most common words that appear before and after, see if there's any in common\n",
    "import requests\n",
    "words = ds[3]['words']\n",
    "suffixes = {}\n",
    "for word in words:\n",
    "  response = requests.get(f\"https://api.datamuse.com/words?sp={word}*\")\n",
    "  response = response.json()\n",
    "  for result in response:\n",
    "    if len(result['word']) > len(word) and result['word'][len(word):] not in suffixes:\n",
    "      suffixes[result['word'][len(word):]] = result['score']\n",
    "    elif len(result['word']) > len(word):\n",
    "      suffixes[result['word'][len(word):]] += result['score']\n",
    "\n",
    "sorted_suffixes = sorted(suffixes.items(), key=lambda x: x[1], reverse=True)\n",
    "print(sorted_suffixes[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'words': ['spider', 'iron', 'super', 'bat'], 'reason': '___ man superheroes'}, 3), ({'words': ['star', 'silver', 'jelly', 'cray'], 'reason': '___ fish that aren’t fish'}, 6), ({'words': ['bean', 'clean', 'peanut', 'fox'], 'reason': 'mr. ___'}, 15), ({'words': ['bermuda', 'love', 'right', 'acute'], 'reason': '___ triangle'}, 16), ({'words': ['baby', 'wayne', 'kim', 'jon'], 'reason': 'lil ___ rappers'}, 20), ({'words': ['bite', 'wave', 'barrier', 'asleep'], 'reason': 'sound ___'}, 21), ({'words': ['pot', 'ass', 'rabbit', 'knife'], 'reason': 'jack ___'}, 26), ({'words': ['copy', 'alley', 'cool', 'lap'], 'reason': '___ cat'}, 28), ({'words': ['cement', 'soul', 'band', 'duckie'], 'reason': 'rubber ___'}, 31), ({'words': ['half', 'neck', 'so', 'again'], 'reason': '___ and ___'}, 34), ({'words': ['eye', 'truth', 'gun', 'mole rat'], 'reason': 'naked ___'}, 35), ({'words': ['pepper', 'evil', 'no', 'j'], 'reason': 'dr. ___'}, 38), ({'words': ['jungle', 'house', 'fat', 'doja'], 'reason': '___ cat'}, 41), ({'words': ['lost', 'beach', 'beastie', 'hardy'], 'reason': '___ boys'}, 42), ({'words': ['alarm', 'grandfather', 'biological', 'cuckoo'], 'reason': '___ clock'}, 48), ({'words': ['rocky', 'high', 'silk', 'abbey'], 'reason': '___ road'}, 53), ({'words': ['memory', 'selfie', 'hockey', 'fish'], 'reason': '___ stick'}, 54), ({'words': ['match', 'west', 'selling', 'moot'], 'reason': '___ point'}, 60), ({'words': ['bone', 'shirt', 'storm', 'rex'], 'reason': 't-___'}, 63), ({'words': ['meal', 'root', 'dance', 'one'], 'reason': 'square ___'}, 66), ({'words': ['carrot', 'sponge', 'coffee', 'pound'], 'reason': '___ cake'}, 67), ({'words': ['meal', 'hour', 'medium', 'camper'], 'reason': 'happy ___'}, 69), ({'words': ['hawk', 'montana', 'stark', 'soprano'], 'reason': 'tony ___'}, 70), ({'words': ['taste', 'santa', 'boys', 'lieutenant'], 'reason': '“bad ___” movies'}, 71), ({'words': ['island', 'bunny', 'egg', 'sunday'], 'reason': 'easter ___'}, 74), ({'words': ['top ten', 'guest', 'bucket', 'wish'], 'reason': '___ list'}, 77), ({'words': ['apple', 'cracker', 'flap', 'lumber'], 'reason': '___jack'}, 80), ({'words': ['folding', 'high', 'lawn', 'first'], 'reason': '___ chair'}, 84), ({'words': ['scotch', 'red', 'ticker', 'demo'], 'reason': '___ tape'}, 88), ({'words': ['legs', 'lion', 'cucumber', 'change'], 'reason': 'sea ___'}, 90), ({'words': ['beanie', 'fur', 'santa', 'nepo'], 'reason': '___ baby'}, 93), ({'words': ['new york', \"rock 'n roll\", 'you', 'lucy'], 'reason': 'i love ___'}, 96), ({'words': ['laundry', 'martini', 'joke', 'dozen'], 'reason': 'dirty ___'}, 99), ({'words': ['star', 'hover', 'key', 'dash'], 'reason': '___board'}, 102), ({'words': ['monty', 'moon', 'circle', 'house'], 'reason': 'full ___'}, 106), ({'words': ['bulb', 'beer', 'year', 'rail'], 'reason': 'light ___'}, 108), ({'words': ['ballpark', 'stick', 'go', 'action'], 'reason': '___ figure'}, 111), ({'words': ['speech', 'water', 'lead', 'trial'], 'reason': '___ balloon'}, 113), ({'words': ['gaga', 'luck', 'macbeth', 'bird'], 'reason': 'lady ___'}, 116), ({'words': ['rock', 'soap', 'comic', 'met'], 'reason': '___ opera'}, 118), ({'words': ['nap', 'plant', 'ranger', 'trip'], 'reason': 'power ___'}, 120), ({'words': ['butcher', 'wax', 'toilet', 'scrap'], 'reason': '___ paper'}, 121), ({'words': ['creator', 'rapper', 'stallion', 'dude'], 'reason': '“the(e) ___” rappers'}, 123), ({'words': ['cat', 'chance', 'lip', 'tuesday'], 'reason': 'fat ___'}, 126), ({'words': ['garden', 'star', 'candy', 'bottom'], 'reason': 'rock ___'}, 127), ({'words': ['food', 'fashion', 'forward', 'friends'], 'reason': 'fast ___'}, 129), ({'words': ['impossible', 'good', 'nothing', 'warren'], 'reason': '___ burger'}, 130), ({'words': ['candy', 'copy', 'seltzer', 'knocks'], 'reason': 'hard ___'}, 133), ({'words': ['maple', 'simple', 'cough', 'corn'], 'reason': '___ syrup'}, 135), ({'words': ['new', 'sailor', 'harvest', 'blue'], 'reason': '___ moon'}, 138), ({'words': ['hot', 'belly', 'snooze', 'panic'], 'reason': '___ button'}, 140), ({'words': ['yellow', 'sports', 'life', 'dust'], 'reason': '___ jacket'}, 141), ({'words': ['we', 'jelly', 'family', 'flush'], 'reason': 'royal ___'}, 144), ({'words': ['divine', 'sketch', 'prop', 'black'], 'reason': '___ comedy'}, 150), ({'words': ['room', 'clue', 'grip', 'life'], 'reason': '“get a ___!”'}, 152), ({'words': ['fire', 'adam', 'red', 'carpenter'], 'reason': '___ ant'}, 155), ({'words': ['white', 'lake', 'seal', 'dane'], 'reason': 'great ___'}, 157), ({'words': ['may', 'labor', 'earth', 'groundhog'], 'reason': '___ day holidays'}, 160), ({'words': ['mouse', 'lily', 'bachelor', 'maxi'], 'reason': '___ pad'}, 165), ({'words': ['justice', 'ivy', 'little', 'premier'], 'reason': '___ league'}, 167), ({'words': ['bag', 'counter', 'dip', 'sprout'], 'reason': 'bean ___'}, 169), ({'words': ['cottage', 'cream', 'string', 'say'], 'reason': '___ cheese'}, 171), ({'words': ['nba', 'paper', 'pearl', 'traffic'], 'reason': '___ jam'}, 173), ({'words': ['steam', 'hair', 'lettuce', 'state'], 'reason': 'head of ___'}, 175), ({'words': ['construction', 'paper', 'whooping', 'frasier'], 'reason': '___ crane'}, 176), ({'words': ['pom', 'yo', 'boo', 'tom'], 'reason': '___-___'}, 178), ({'words': ['rice', 'note', 'fingers', 'wicket'], 'reason': 'sticky ___'}, 180), ({'words': ['pages', 'bone', 'business', 'girl'], 'reason': 'funny ___'}, 181), ({'words': ['spoon', 'screen', 'fox', 'lining'], 'reason': 'silver ___'}, 183), ({'words': ['fin', 'ice', 'ire', 'green'], 'reason': '___land'}, 187), ({'words': ['amateur', 'happy', 'rush', 'eleventh'], 'reason': '___ hour'}, 189), ({'words': ['hidden', 'silicon', 'uncanny', 'death'], 'reason': '___ valley'}, 192), ({'words': ['blue', 'straw', 'goose', 'rasp'], 'reason': '___berry '}, 194), ({'words': ['santa', 'sauce', 'code', 'agent'], 'reason': 'secret ___'}, 196), ({'words': ['ghost', 'bell', 'black', 'dr'], 'reason': '___ pepper'}, 198), ({'words': ['saint', 'boy', 'by', 'curious'], 'reason': '___ george'}, 200), ({'words': ['bear', 'sand', 'speed', 'tourist'], 'reason': '___ trap'}, 201), ({'words': ['wonder', 'talk', 'world', 'fry'], 'reason': 'small ___'}, 204), ({'words': ['charm', 'strike', 'duck', 'break'], 'reason': 'lucky ___'}, 206), ({'words': ['disco', 'crystal', 'gutter', 'foul'], 'reason': '___ ball'}, 208), ({'words': ['wisdom', 'baby', 'eye', 'sweet'], 'reason': '___ tooth'}, 210), ({'words': ['perfect', 'elevator', 'fever', 'sales'], 'reason': '___ pitch'}, 213), ({'words': ['soup', 'pod', 'coat', 'green'], 'reason': 'pea ___'}, 217), ({'words': ['love', 'cover', 'scarlet', 'chain'], 'reason': '___ letter'}, 220), ({'words': ['talk', 'shower', 'carrot', 'boom'], 'reason': 'baby ___'}, 222), ({'words': ['school', 'gap', 'light', 'leap'], 'reason': '___ year'}, 224), ({'words': ['time', 'bar', 'torch', 'buck'], 'reason': 'pass the ___'}, 225), ({'words': ['dust', 'honey', 'bad', 'bugs'], 'reason': '___ bunny'}, 228), ({'words': ['cell', 'number', 'contact', 'digits'], 'reason': '“can i get your ___?” (phone info request)'}, 230), ({'words': ['tar', 'orchestra', 'snake', 'barbecue'], 'reason': '___ pit'}, 234), ({'words': ['drift', 'sandal', 'holly', 'dog'], 'reason': '___wood'}, 235), ({'words': ['dragon', 'butter', 'horse', 'fire'], 'reason': '___fly'}, 239), ({'words': ['family', 'flea', 'flying', 'media'], 'reason': '___ circus'}, 240), ({'words': ['pants', 'free', 'that', 'feast'], 'reason': 'fancy ___'}, 243), ({'words': ['claw', 'hug', 'fruit', 'witness'], 'reason': 'bear ___'}, 244), ({'words': ['figure', 'steady', 'fish', 'bananas'], 'reason': 'go ___'}, 246), ({'words': ['pod', 'type', 'broad', 'fore'], 'reason': '___cast'}, 251), ({'words': ['fish', 'hard knocks', 'rock', 'thought'], 'reason': 'school of ___'}, 253), ({'words': ['salmon', 'rope', 'word', 'corporate'], 'reason': '___ ladder'}, 256), ({'words': ['fruit', 'baseball', 'cricket', 'vampire'], 'reason': '___ bat'}, 257), ({'words': ['dance', 'flop', 'button', 'laugh'], 'reason': 'belly ___'}, 263), ({'words': ['space', 'dutch', 'jeopardy', 'date'], 'reason': 'double ___'}, 265), ({'words': ['large', 'legend', 'room', 'proof'], 'reason': 'living ___'}, 267), ({'words': ['pipe', 'fever', 'american', 'lucid'], 'reason': '___ dream'}, 269), ({'words': ['day', 'jell', 'jackie', 'daddy'], 'reason': '___-o'}, 271), ({'words': ['cadet', 'bar', 'heater', 'station'], 'reason': 'space ___'}, 276), ({'words': ['cradle', 'meow', 'pajamas', 'eye'], 'reason': 'cat’s ___'}, 278), ({'words': ['dirty', 'date', 'doh', 'dead'], 'reason': 'play ___'}, 279), ({'words': ['guess', 'wind', 'nature', 'fiddle'], 'reason': 'second ___'}, 281), ({'words': ['color', 'hamster', 'cheese', 'prayer'], 'reason': '___ wheel'}, 286), ({'words': ['medicine', 'prompter', 'commute', 'vision'], 'reason': 'tele___'}, 287), ({'words': ['computer', 'blue', 'potato', 'poker'], 'reason': '___ chip'}, 289), ({'words': ['joker', 'sinner', 'smoker', 'lover'], 'reason': '“i’m a ___” (lyrics in “the joker”)'}, 293), ({'words': ['honey', 'brown', 'teddy', 'boo-boo'], 'reason': '___ bear'}, 295), ({'words': ['gift', 'shrink', 'bubble', 'body'], 'reason': '___ wrap'}, 297), ({'words': ['crazy', 'gift', 'charley', 'dark'], 'reason': '___ horse'}, 302), ({'words': ['power', 'shoe', 'fly', 'radish'], 'reason': 'horse___'}, 303), ({'words': ['drum', 'wig', 'wax', 'mark'], 'reason': 'ear___'}, 309), ({'words': ['girls', 'parachute', 'rule', 'fleece'], 'reason': 'golden ___'}, 311), ({'words': ['rod', 'plus', 'list', 'ok'], 'reason': 'a-___'}, 312), ({'words': ['side', 'butterfly', 'domino', 'placebo'], 'reason': '___ effect'}, 313), ({'words': ['proud', 'virgin', 'hail', 'bloody'], 'reason': '___ mary'}, 320), ({'words': ['body', 'sign', 'love', 'romance'], 'reason': '___ language'}, 321), ({'words': ['garage', 'clearance', 'sample', 'bake'], 'reason': '___ sale'}, 326), ({'words': ['queen', 'honey', 'busy', 'spelling'], 'reason': '___ bee'}, 327), ({'words': ['sponge', 'bird', 'mud', 'bubble'], 'reason': '___ bath'}, 328), ({'words': ['music', 'med', 'sandwich', 'soda'], 'reason': 'club ___'}, 330), ({'words': ['applause', 'golf', 'drinks', 'funding'], 'reason': 'round of ___'}, 331), ({'words': ['pong', 'garden', 'batter', 'can'], 'reason': 'beer ___'}, 338), ({'words': ['wet', 'security', 'picnic', 'throw'], 'reason': '___ blanket'}, 339), ({'words': ['jim', 'shady', 'fit', 'pickings'], 'reason': 'slim ___'}, 341), ({'words': ['match', 'face', 'pocket', 'mac'], 'reason': '___book (that’s not a book)'}, 347), ({'words': ['sea', 'chump', 'loose', 'climate'], 'reason': '___ change'}, 348), ({'words': ['bull', 'meat', 'stock', 'flea'], 'reason': '___ market'}, 350), ({'words': ['hood', 'fuji', 'olympus', 'whitney'], 'reason': 'mount ___'}, 351), ({'words': ['safety', 'push', 'bobby', 'hair'], 'reason': '___ pin'}, 352), ({'words': ['tire', 'pump', 'waffle', 'steam'], 'reason': '___ iron'}, 354), ({'words': ['please', 'woman', 'good', 'penny'], 'reason': 'pretty ___'}, 359), ({'words': ['school', 'movie', 'ball', 'vitamin'], 'reason': 'b-___'}, 362), ({'words': ['span', 'clef', 'section', 'suite'], 'reason': 'c-___'}, 363), ({'words': ['flower', 'problem', 'poster', 'only'], 'reason': '___ child'}, 365), ({'words': ['fish', 'folk', 'fairy', 'tall'], 'reason': '___ tale'}, 371), ({'words': ['baked', 'sweet', 'couch', 'hot'], 'reason': '___ potato'}, 372), ({'words': ['bug', 'bolt', 'strike', 'rod'], 'reason': 'lightning ___'}, 376), ({'words': ['carpet', 'meat', 'delicious', 'tape'], 'reason': 'red ___'}, 377), ({'words': ['bond', 'rush', 'leaf', 'mine'], 'reason': 'gold ___'}, 378), ({'words': ['personal', 'pop-up', 'want', 'attack'], 'reason': '___ ad'}, 379), ({'words': ['magic', 'sin', 'windy', 'motor'], 'reason': '___ city nicknames'}, 382), ({'words': ['may', 'sun', 'wall', 'wild'], 'reason': '___flower'}, 383), ({'words': ['dog', 'phone', 'freeze', 'price'], 'reason': '___ tag'}, 385), ({'words': ['squid', 'arcade', 'numbers', 'blame'], 'reason': '___ game'}, 388), ({'words': ['mother', 'grey', 'golden', 'silly'], 'reason': '___ goose'}, 393), ({'words': ['pan', 'rabbit', 'parker', 'piper'], 'reason': 'peter ___'}, 400), ({'words': ['coffee', 'water', 'pool', 'periodic'], 'reason': '___ table'}, 405), ({'words': ['pyramid', 'chain', 'fight', 'processor'], 'reason': 'food ___'}, 406), ({'words': ['talk', 'pirate', 'ham', 'satellite'], 'reason': '___ radio'}, 412), ({'words': ['bulldog', 'kiss', 'horn', 'fry'], 'reason': 'french ___'}, 413), ({'words': ['tube', 'crew', 'sweat', 'ankle'], 'reason': '___ socks'}, 416), ({'words': ['horror', 'jock', 'wave', 'value'], 'reason': 'shock ___'}, 419), ({'words': ['shoe', 'bull', 'fog', 'matter'], 'reason': '___horn'}, 422), ({'words': ['wheel', 'porter', 'rough', 'power'], 'reason': '___house (that aren’t houses)'}, 433), ({'words': ['teeth', 'steps', 'boomer', 'blues'], 'reason': 'baby ___'}, 439), ({'words': ['store', 'reaction', 'letter', 'mail'], 'reason': 'chain ___'}, 447), ({'words': ['cube', 'machine', 'cream', 'storm'], 'reason': 'ice ___'}, 449), ({'words': ['fore', 'arrow', 'knuckle', 'block'], 'reason': '___head'}, 452), ({'words': ['beach', 'pet shop', 'hardy', 'bad'], 'reason': '___ boys'}, 453), ({'words': ['lion', 'burger', 'prom', 'california'], 'reason': '___ king'}, 465), ({'words': ['parallel', 'south', 'amusement', 'national'], 'reason': '___ park'}, 468), ({'words': ['home run', 'soap box', 'kentucky', 'demolition'], 'reason': '___ derby'}, 473), ({'words': ['bikini', 'cheese', 'bean', 'theory'], 'reason': 'string ___'}, 474), ({'words': ['quality', 'birth', 'remote', 'cruise'], 'reason': '___ control'}, 475), ({'words': ['jeans', 'jay', 'moon', 'whale'], 'reason': 'blue ___'}, 476), ({'words': ['goblin', 'beret', 'thumb', 'salad'], 'reason': 'green ___'}, 476), ({'words': ['rain', 'haze', 'heart', 'prose'], 'reason': 'purple ___'}, 476), ({'words': ['jacket', 'cab', 'pages', 'journalism'], 'reason': 'yellow ___'}, 476), ({'words': ['dream', 'dinner', 'due', 'delivery'], 'reason': '___ date'}, 480), ({'words': ['cream', 'cottage', 'goat', 'string'], 'reason': '___ cheese'}, 484), ({'words': ['cane', 'bar', 'apple', 'corn'], 'reason': 'candy ___'}, 485), ({'words': ['california', 'egg', 'drum', 'honor'], 'reason': '___ roll'}, 493), ({'words': ['egg', 'witch', 'job', 'scavenger'], 'reason': '___ hunt'}, 494), ({'words': ['river', 'prime', 'rainforest', 'kindle'], 'reason': 'amazon ___'}, 495), ({'words': ['harvard', 'lemon', 'natural', 'criminal'], 'reason': '___ law'}, 496), ({'words': ['whirl', 'liver', 'car', 'dead'], 'reason': '___pool'}, 501), ({'words': ['times', 'town', 'pocket', 'perfect'], 'reason': '___ square'}, 503), ({'words': ['domino', 'butterfly', 'halo', 'placebo'], 'reason': '___ effect'}, 504), ({'words': ['prince', 'mermaid', 'tramp', 'rascals'], 'reason': 'the little ___'}, 505), ({'words': ['street', 'money', 'listening', 'chair'], 'reason': 'easy ___'}, 509), ({'words': ['cheese', 'mustard', 'deck', 'cord'], 'reason': 'cut the ___'}, 514), ({'words': ['mushroom', 'kingdom', 'marker', 'carpet'], 'reason': 'magic ___'}, 515), ({'words': ['sue', 'big', 'early', 'lady'], 'reason': '___ bird'}, 518), ({'words': ['jeopardy', 'agent', 'standard', 'dribble'], 'reason': 'double ___'}, 523), ({'words': ['fiddler', 'horseshoe', 'spider', 'hermit'], 'reason': '___ crab'}, 526), ({'words': ['rogue', 'commando', 'figure', 'bananas'], 'reason': 'go ___'}, 528), ({'words': ['fantasy', 'love', 'shutter', 'treasure'], 'reason': '“___ island”'}, 529), ({'words': ['rubber', 'tribute', 'wedding', 'boy'], 'reason': '___ band'}, 530), ({'words': ['passage', 'waste', 'nick', 'sands'], 'reason': '___ of time'}, 532), ({'words': ['fast', 'screw', 'knuckle', 'curve'], 'reason': '___ball pitches'}, 536), ({'words': ['paper', 'alligator', 'hair', 'video'], 'reason': '___ clip'}, 537), ({'words': ['solo', 'willy', 'bird', 'fallin’'], 'reason': '“free ___”'}, 538), ({'words': ['giving', 'fat', 'taco', 'super'], 'reason': '___ tuesday'}, 539), ({'words': ['lime', 'yellow', 'rhine', 'brim'], 'reason': '___stone'}, 542), ({'words': ['horn', 'legs', 'fellow', 'bow'], 'reason': 'long___'}, 545), ({'words': ['teapot', 'onion', 'capitol', 'chrome'], 'reason': '___ dome'}, 559), ({'words': ['bowl', '8', 'glue', 'tuesday'], 'reason': 'super ___'}, 561), ({'words': ['paddle', 'tired', 'tag', 'days'], 'reason': 'dog ___'}, 568), ({'words': ['drop', 'game', 'brand', 'names'], 'reason': 'name ___'}, 569), ({'words': ['sticker', 'belly', 'hole', 'luck'], 'reason': 'pot___'}, 572), ({'words': ['book', 'earth', 'inch', 'glow'], 'reason': '___worm'}, 578), ({'words': ['love', 'a rose', 'enough', 'a deal'], 'reason': '___ is ___ (is ___)'}, 579), ({'words': ['supreme', 'food', 'kangaroo', 'tennis'], 'reason': '___ court'}, 580), ({'words': ['cookie', 'cheat', 'fitted', 'balance'], 'reason': '___ sheet'}, 582), ({'words': ['mall', 'gym', 'rug', 'pack'], 'reason': '___ rat'}, 583), ({'words': ['page', 'tide', 'corner', 'tables'], 'reason': 'turn the ___'}, 585), ({'words': ['batter', 'chin', 'lawyer', 'bottoms'], 'reason': '___ up'}, 590), ({'words': ['nicotine', 'rough', 'cabbage', 'soul'], 'reason': '___ patch'}, 592), ({'words': ['gingerbread', 'full', 'haunted', 'white'], 'reason': '___ house'}, 593), ({'words': ['demon', 'chess', 'bump', 'dial'], 'reason': 'speed ___'}, 594), ({'words': ['match', 'chord', 'deal', 'pose'], 'reason': 'strike a ___'}, 598), ({'words': ['fast', 'soul', 'finger', 'junk'], 'reason': '___ food'}, 608), ({'words': ['velvet', 'bull', 'cross', 'herring'], 'reason': 'red ___'}, 609), ({'words': ['mad', 'hub', 'night', 'knee'], 'reason': '___cap'}, 610), ({'words': ['cheese', 'pan', 'cup', 'short'], 'reason': '___cake'}, 614), ({'words': ['guilt', 'ego', 'power', 'head'], 'reason': '___ trip'}, 615), ({'words': ['cock', 'pony', 'mock', 'pig'], 'reason': '___tail'}, 622), ({'words': ['blow', 'cat', 'sword', 'gold'], 'reason': '___fish'}, 623)]\n"
     ]
    }
   ],
   "source": [
    "# get all groups that have \"___\" in reason\n",
    "groups_with_underscore = []\n",
    "for game in ds:\n",
    "  for group in game['solution']['groups']:\n",
    "    if '___' in group['reason']: # append tuple of word group and game index\n",
    "      groups_with_underscore.append((group, ds.index(game)))\n",
    "\n",
    "print(groups_with_underscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('power', 5.0), ('free', 4.0), ('electronic', 4.0), ('active', 3.0), ('flat', 3.0), ('micro', 3.0), ('kill', 3.0), ('ice', 3.0), ('inter', 3.0), ('counter', 3.0), ('anti', 3.0), ('e-', 3.0), ('retail', 3.0), ('t', 3.0), ('rat', 3.0), ('press', 3.0)]\n",
      "=======================\n",
      "[('rat', 9.0), ('rats', 5.0), ('ers', 4.0), ('off', 4.0), ('on', 4.0), ('d', 4.0), ('ings', 3.0), ('cycle', 3.0), ('board', 3.0), ('el', 3.0), ('man', 3.0), ('men', 3.0), ('department', 3.0), ('en', 3.0), ('name', 3.0)]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_affixes_for_word(word, datamuse_results, mode=\"suffix\"):\n",
    "    affixes = []\n",
    "    for entry in datamuse_results:\n",
    "        result_word = entry['word']\n",
    "        if result_word == word:\n",
    "            continue\n",
    "\n",
    "        if mode == \"suffix\" and result_word.startswith(word):\n",
    "            affix = result_word[len(word):]\n",
    "        elif mode == \"prefix\" and result_word.endswith(word):\n",
    "            affix = result_word[:len(result_word) - len(word)]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        affix = affix.strip()\n",
    "        if affix:\n",
    "            affixes.append(affix)\n",
    "    return affixes\n",
    "\n",
    "def compute_group_affix_scores(group_data, general_affix_freq=None, mode=\"suffix\"):\n",
    "    group_affix_freq = defaultdict(int)\n",
    "\n",
    "    COMMON_AFFIXES = {\n",
    "        \"s\", \"es\", \"ed\", \"ing\", \"er\", \"est\", \"ly\", \"y\", \"e\", \"a\", \"able\", \"ible\", \n",
    "        \"al\", \"ous\", \"ment\", \"ful\", \"less\", \"tion\", \"ness\", \"ant\", \"ent\", \"ive\",\n",
    "        \"ic\", \"ary\", \"ate\", \"an\", \"ian\", \"or\", \"ism\", \"ist\", \"ish\", \"like\", \"ier\",\n",
    "        \"up\", \"down\", \"back\", \"pre\", \"re\", \"un\", \"in\", \"im\", \"non\", \"dis\", \"over\", \"under\"\n",
    "    }\n",
    "\n",
    "    for word, results in group_data.items():\n",
    "        affixes = get_affixes_for_word(word, results, mode=mode)\n",
    "        for affix in affixes:\n",
    "            if affix not in COMMON_AFFIXES:\n",
    "                group_affix_freq[affix] += 1\n",
    "\n",
    "    scores = {}\n",
    "    for affix, freq in group_affix_freq.items():\n",
    "        general_freq = general_affix_freq.get(affix, 1) if general_affix_freq else 1\n",
    "        scores[affix] = freq / general_freq\n",
    "\n",
    "    sorted_affixes = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    sorted_affixes = [affix for affix in sorted_affixes if affix[1] >= 3]\n",
    "    return sorted_affixes\n",
    "\n",
    "\n",
    "words = ds[583]['words']\n",
    "prefix_data = {}\n",
    "suffix_data = {}\n",
    "for word in words:\n",
    "    p_response = requests.get(f\"https://api.datamuse.com/words?sp=*{word}\")\n",
    "    prefix_data[word] = p_response.json()\n",
    "    s_response = requests.get(f\"https://api.datamuse.com/words?sp={word}*\")\n",
    "    suffix_data[word] = s_response.json()\n",
    "\n",
    "print(compute_group_affix_scores(prefix_data, mode=\"prefix\"))\n",
    "print(\"=======================\")\n",
    "print(compute_group_affix_scores(suffix_data, mode=\"suffix\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting osmnx\n",
      "  Downloading osmnx-2.0.2-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: geopandas>=1.0 in c:\\users\\eric\\appdata\\roaming\\python\\python312\\site-packages (from osmnx) (1.0.1)\n",
      "Requirement already satisfied: networkx>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from osmnx) (3.3)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\programdata\\anaconda3\\lib\\site-packages (from osmnx) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from osmnx) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from osmnx) (2.32.3)\n",
      "Requirement already satisfied: shapely>=2.0 in c:\\users\\eric\\appdata\\roaming\\python\\python312\\site-packages (from osmnx) (2.0.6)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in c:\\users\\eric\\appdata\\roaming\\python\\python312\\site-packages (from geopandas>=1.0->osmnx) (0.10.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\eric\\appdata\\roaming\\python\\python312\\site-packages (from geopandas>=1.0->osmnx) (23.2)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in c:\\users\\eric\\appdata\\roaming\\python\\python312\\site-packages (from geopandas>=1.0->osmnx) (3.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\eric\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.4->osmnx) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.4->osmnx) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.4->osmnx) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.27->osmnx) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.27->osmnx) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.27->osmnx) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.27->osmnx) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\eric\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas>=1.4->osmnx) (1.16.0)\n",
      "Downloading osmnx-2.0.2-py3-none-any.whl (99 kB)\n",
      "Installing collected packages: osmnx\n",
      "Successfully installed osmnx-2.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install osmnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric\\AppData\\Roaming\\Python\\Python312\\site-packages\\osmnx\\_overpass.py:267: UserWarning: This area is 36 times your configured Overpass max query area size. It will automatically be divided up into multiple sub-queries accordingly. This may take a long time.\n",
      "  multi_poly_proj = utils_geo._consolidate_subdivide_geometry(poly_proj)\n"
     ]
    }
   ],
   "source": [
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import folium\n",
    "\n",
    "# 1. Starting point (Amherst, MA)\n",
    "start_lat, start_lon = 42.3732, -72.5199\n",
    "start_point = (start_lat, start_lon)\n",
    "\n",
    "# 2. Download road network\n",
    "G = ox.graph_from_point(start_point, dist=150000, network_type='drive')\n",
    "\n",
    "# 3. Find nearest node\n",
    "orig_node = ox.nearest_nodes(G, X=start_lon, Y=start_lat)\n",
    "\n",
    "# 4. Calculate shortest paths within 90 miles (144,840 meters)\n",
    "max_dist = 144840\n",
    "distances = nx.single_source_dijkstra_path_length(G, orig_node, cutoff=max_dist, weight='length')\n",
    "\n",
    "# 5. Visualize\n",
    "reachable_nodes = list(distances.keys())\n",
    "subgraph = G.subgraph(reachable_nodes)\n",
    "ox.plot_graph_folium(subgraph, popup_attribute='length', tiles='cartodbpositron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['market',\n",
       " 'switch',\n",
       " 'plant',\n",
       " 'mall',\n",
       " 'trade',\n",
       " 'gym',\n",
       " 'outlet',\n",
       " 'asset',\n",
       " 'rug',\n",
       " 'business',\n",
       " 'mole',\n",
       " 'sconce',\n",
       " 'pack',\n",
       " 'agent',\n",
       " 'baseboard',\n",
       " 'commerce']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[583]['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('minneapolis', 0.728505551815033),\n",
       " ('portland', 0.7126332521438599),\n",
       " ('vancouver', 0.6863006949424744),\n",
       " ('calgary', 0.6720302104949951),\n",
       " ('philadelphia', 0.6713477373123169),\n",
       " ('baltimore', 0.6664227247238159),\n",
       " ('houston', 0.6611942052841187),\n",
       " ('denver', 0.6545454859733582),\n",
       " ('melbourne', 0.6510372757911682),\n",
       " ('pittsburgh', 0.6482068300247192)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wiki = api.load('fasttext-wiki-news-subwords-300')\n",
    "model_wiki.most_similar('seattle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8519377"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wiki.similarity('pushup', 'push-up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'words': ['dust',\n",
       "  'cats',\n",
       "  'spider',\n",
       "  'carousel',\n",
       "  'puma',\n",
       "  'iron',\n",
       "  'nike',\n",
       "  'mop',\n",
       "  'chicago',\n",
       "  'sweep',\n",
       "  'super',\n",
       "  'bat',\n",
       "  'reebok',\n",
       "  'cabaret',\n",
       "  'vacuum',\n",
       "  'adidas'],\n",
       " 'solution': {'groups': [{'words': ['spider', 'iron', 'super', 'bat'],\n",
       "    'reason': '___ man superheroes'},\n",
       "   {'words': ['dust', 'mop', 'sweep', 'vacuum'], 'reason': 'cleaning verbs'},\n",
       "   {'words': ['cats', 'carousel', 'chicago', 'cabaret'],\n",
       "    'reason': 'musicals beginning with “c”'},\n",
       "   {'words': ['puma', 'nike', 'reebok', 'adidas'],\n",
       "    'reason': 'sneaker brands'}]}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
